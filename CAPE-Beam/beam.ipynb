{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b013e12e-83b3-4bf4-9656-00ccc79c0031",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b49a2e6c-01ca-49c3-a2b5-d138247113f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import shutil\n",
    "import re\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import copy\n",
    "from tqdm.auto import tqdm\n",
    "import glasbey\n",
    "\n",
    "import Levenshtein\n",
    "\n",
    "import statsmodels.api as sm\n",
    "from scipy import stats\n",
    "\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "from matplotlib.ticker import PercentFormatter\n",
    "import glasbey\n",
    "import seaborn as sns\n",
    "import string\n",
    "\n",
    "from Bio import Align\n",
    "from Bio.Align import substitution_matrices\n",
    "\n",
    "import kit\n",
    "import kit.globals as G\n",
    "from kit.loch.oo import Loch\n",
    "from kit.loch.path import cp_fasta_to_dir\n",
    "from kit.path import join, get_entries\n",
    "from kit.data import DD, Split, file_to_str, str_to_file\n",
    "from kit.data.utils import set_df_cols_to, cast_df_cols_to\n",
    "from kit.data.trees import PrefixTree\n",
    "from kit.bioinf import get_kmers\n",
    "from kit.bioinf.alignment.structure.tm_align import align_structures\n",
    "from kit.bioinf.immuno.mhc_1 import Mhc1Predictor, MHC_1_PEPTIDE_LENGTHS\n",
    "from kit.bioinf.immuno.utils import get_mhc_1_setup_hash\n",
    "from kit.bioinf.utils import get_seq_hash\n",
    "from kit.bioinf.utils.filter import filter_pdbs\n",
    "from kit.bioinf.proteins.similar import get_similar_proteins\n",
    "from kit.bioinf.proteins import Protein, ProteinType\n",
    "from kit.bioinf.pdb import download_structure, includes_dna, check_xray, get_protein_name_organism\n",
    "from kit.bioinf.fasta import fasta_to_df, read_fasta\n",
    "from kit.plot import A4_height, A4_width, plot_text, plot_legend_patches\n",
    "\n",
    "from CAPE.MPNN import run_mpnn\n",
    "from CAPE.MPNN.model import CapeMPNN\n",
    "from CAPE.MPNN.data.aux import S_to_seqs\n",
    "from CAPE.MPNN.beam import set_config as set_config_beam, get_beam_search_hash, get_features_from_pdb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "158cd55d-2060-4601-96bf-1e767bb5b687",
   "metadata": {},
   "source": [
    "# Startup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39b8238c-7bcc-443f-97f5-b2a26c4cb869",
   "metadata": {},
   "outputs": [],
   "source": [
    "args, args_unknown = kit.init('CAPE', 'CAPE-Beam', create_job=False, arg_string=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc8f6e45-463d-4566-89f5-fe0cd0360560",
   "metadata": {},
   "outputs": [],
   "source": [
    "G.DOMAIN = 'v2'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54575bb4-8582-40d0-a6ae-42cbc502077d",
   "metadata": {},
   "source": [
    "# Configs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f2896c4-c4ef-4150-98af-058eaa0ea093",
   "metadata": {},
   "source": [
    "## Design"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54173690-57af-4c31-8cb8-4ea4d12808a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "kit.DEVICE = 'cpu'\n",
    "\n",
    "BASE_MODEL_NAME = 'v_48_020'\n",
    "PROTEOME_FILE_NAME = \"2022-05-29-Homo_sapiens_GRCh38_biomart_v94.fasta\"\n",
    "ALPHABET = 'ACDEFGHIKLMNPQRSTVWYX'\n",
    "\n",
    "MHC_1_PREDICTOR_DECODING = 'pwm_dynamic'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e56ab2c-1f22-4216-b523-b31e9af45670",
   "metadata": {},
   "source": [
    "## Hyper-parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9601c015-0552-44dd-a8ad-6c345ca3eac3",
   "metadata": {},
   "outputs": [],
   "source": [
    "NON_SELF_PROB_FACTORS = [0., 0.01, 0.1, 0.25, 0.5, 0.9, 0.95, 0.99, 0.999]\n",
    "NON_SELF_PROB_FACTORS = [0., 0.1, 0.5, 0.9, 0.99]\n",
    "MIN_PROTEOME_KMER_LENS = [5, 6, 7]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91bc4514-9690-42b1-b012-5290878b3e21",
   "metadata": {},
   "source": [
    "## Genotypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f90ed2f-119f-461f-b504-f79745cb4aff",
   "metadata": {},
   "outputs": [],
   "source": [
    "person_mhc_1_genotype = \"HLA-A*02:01+HLA-A*24:02+HLA-B*07:02+HLA-B*39:01+HLA-C*07:01+HLA-C*16:01\"\n",
    "person_mhc_1_genotype_list = person_mhc_1_genotype.split(\"+\")\n",
    "\n",
    "alternative_mhc_1_genotypes = [\"HLA-A*29:02+HLA-A*30:07+HLA-B*15:13+HLA-B*57:01+HLA-C*14:02+HLA-C*04:04\"]\n",
    "\n",
    "all_mhc_1_genotypes = [person_mhc_1_genotype] + alternative_mhc_1_genotypes\n",
    "\n",
    "immuno_setup = {'mhc_1': person_mhc_1_genotype}\n",
    "\n",
    "DISTANCE_RANK_THRESHOLD = 0.02  # used to identify alternative genotypes\n",
    "\n",
    "ANALYSE_PWM_PREDICTOR = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e113c5a5-e269-4b0a-b680-56a37be597ca",
   "metadata": {},
   "source": [
    "## Protein Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6883a8e-3a78-49ba-ba1d-6ec5c1881c45",
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 42\n",
    "MIN_SPECIFIC_CHAIN_LENGTH = 51\n",
    "MAX_PROTEIN_LENGTH = 2000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f7a2953-85a5-449a-b527-489cd0d16497",
   "metadata": {},
   "outputs": [],
   "source": [
    "SPECIFIC_MANUAL = {\n",
    "    # Split.VAL: sorted(['1B9K', '1OA4', '1QWK', '1TJE', '1XGD', '4RQG']),\n",
    "    Split.VAL: sorted(['1B9K', '1OA4', '1QWK', '1TEJ', '1TJE', '1UIZ', '1XGD', '2C2X', '2QT4', '4RQG', '1QTS', '6Q3V', '4BVK', '2R90', '5XBH']),\n",
    "    Split.TEST: sorted(['1A3H', '1P3C', '1PGS', '1QKD', '1S5T', '1X0M', '2BK8', '3O6A', '3TIP', '3WOY',\n",
    "                        '4BOK', '4QTZ', '1A2O', '5OA9', '6PNW', '3SFT', '5V5F', '6TPT', '5TPJ', '3RFW']),\n",
    "    Split.PREDICT: [],\n",
    "}\n",
    "\n",
    "N_SPECIFIC = {\n",
    "    Split.VAL: 15,\n",
    "    Split.TEST: 20,\n",
    "    Split.PREDICT: 0\n",
    "}\n",
    "\n",
    "IDENTIFY_SPECIFIC = True if any(len(SPECIFIC_MANUAL[split]) < N_SPECIFIC[split] for split in [Split.VAL, Split.TEST, Split.PREDICT]) else False\n",
    "LOAD_RESULTS = None\n",
    "\n",
    "CANDIDATE_MAX_UNMODELLED = 5\n",
    "CANDIDATE_EXCLUDE_SMALL_MOLECULES = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00a74e76-36f9-47e6-a1e7-e1ec759348f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "SIMILAR_MIN_PROTEINS_CNT = 3\n",
    "SIMILAR_MAX_PROTEINS_CNT = 10\n",
    "\n",
    "SIMILAR_MAX_SCORE = 0.99\n",
    "SIMILAR_MIN_SCORE = 0.1\n",
    "SIMILAR_MIN_TM_SCORE = 0.9\n",
    "SIMILAR_MAX_LENGTH_DIFF = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fcc7039-473e-47a9-b25d-e512ebeb5d9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "KEEP_CHAINS = {\n",
    "    '1UIZ': ['A', 'B', 'C'],\n",
    "    '4BVK': ['A'],\n",
    "}\n",
    "\n",
    "AF_ERRORS_SEQ_HASHES = [\n",
    "    '409f67caa69e3646d259a003db9e1ae79174e7ab317cf584eab3d0e31c66c4f1', 'e9a929bd99de028d6a03c415b668f0688cca0f98d62d7169e3231056f5383b85',\n",
    "    '86403f1cba1c1f920de5861e20cd71d91b56a226df783a75f24dffaf73d1e8c1', 'fdc5626917d775784984dd415d639b41e3053bb3967ddb5dbeb0ce57b4a11fc5',\n",
    "    'c0f7d4c3dd8b0d83bee7047c164c8dc2fe8f306b0c574614ebc3dc3261ce6ac8'\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d9cc7ce-09ef-4c38-ba29-ac97f6b617ce",
   "metadata": {},
   "source": [
    "## Benchmarks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3753f2a5-ab89-4dd7-9f48-7143c4b2dd9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "SAMPLING_TEMPS = [1e-8, 0.1]\n",
    "\n",
    "benchmark_sources = {\n",
    "    'template': [{'eval_mhc_1_genotype': mhc_alleles} for mhc_alleles in all_mhc_1_genotypes], \n",
    "    'standard': [{'sampling_temp': sampling_temp, 'eval_mhc_1_genotype': mhc_genotype} for sampling_temp in SAMPLING_TEMPS for mhc_genotype in all_mhc_1_genotypes], \n",
    "    'CAPE-MPNN': [{'sampling_temp': sampling_temp, 'tune_mhc_1_genotype': person_mhc_1_genotype, 'eval_mhc_1_genotype': person_mhc_1_genotype} for sampling_temp in SAMPLING_TEMPS]\n",
    "}\n",
    "benchmark_source_ids = list(benchmark_sources.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4efc1b90-fac6-4d0c-b7d8-f48fa43e018f",
   "metadata": {},
   "outputs": [],
   "source": [
    "CAPE_MPNN_WEIGHTS_PATH = os.path.join(G.ENV.PROJECT, 'artefacts', 'CAPE-MPNN', 'models')\n",
    "CAPE_MPNN_CKPT_ID = '458340e4:epoch_20'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13fc424a-9a6a-4329-9c8c-dbde13b0d751",
   "metadata": {},
   "source": [
    "## Figures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed5cfb86-a7ea-47ac-9ed6-e63ad9516c2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig_X_configs = {split: [\n",
    "        {'eval_mhc_1_genotype': (person_mhc_1_genotype,), 'sampling_temp': (None, _sampling_temp)} for _sampling_temp in SAMPLING_TEMPS\n",
    "    ] for split in Split\n",
    "}\n",
    "fig_A_configs = {split: [\n",
    "        {'eval_mhc_1_genotype': (person_mhc_1_genotype,), 'sampling_temp': (None, _sampling_temp)} for _sampling_temp in SAMPLING_TEMPS\n",
    "    ] for split in Split\n",
    "}\n",
    "fig_B_configs = {split: [\n",
    "        {'eval_mhc_1_genotype': (person_mhc_1_genotype,), 'sampling_temp': (None, _sampling_temp)} for _sampling_temp in SAMPLING_TEMPS\n",
    "    ] for split in Split\n",
    "}\n",
    "fig_C_configs = {split: [\n",
    "        {'eval_mhc_1_genotype': (person_mhc_1_genotype,), 'sampling_temp': (None, _sampling_temp)} for _sampling_temp in SAMPLING_TEMPS\n",
    "    ] for split in Split\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c10d22c8-bd40-45df-8c4e-354761403a00",
   "metadata": {},
   "source": [
    "## System"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3174eb02-51cc-4107-b4bd-ddf7ed85a6b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "SAVE_FIGURES = True\n",
    "OVERWRITE = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47d3ff0b-1523-4663-a51d-f8c31bb73da4",
   "metadata": {},
   "outputs": [],
   "source": [
    "PDB_SERVER = r'https://files.rcsb.org'\n",
    "FASTA_OUTPUT_PATH = join(G.ENV.ARTEFACTS, 'designs')\n",
    "PROTEIN_MPNN_REPO_PATH = os.path.join(G.ENV.PROJECT, 'external', 'repos', 'ProteinMPNN')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab66f95f-b1a2-4bf6-975d-e5c6e7ed68d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "LOCH_PATH = join(G.ENV.ARTEFACTS, 'loch')\n",
    "PDB_DIR_PATH = join(G.ENV.PROJECT, 'data', 'input', 'PDBs')\n",
    "COLABFOLD_PATH = join(G.PROJECT_ENV.ARTEFACTS, 'colabfold')\n",
    "SIMILAR_PROTEINS_PATH = join(G.ENV.ARTEFACTS, 'eval', 'similar_PDBs')\n",
    "\n",
    "GENERAL_DATA_DIR_PATH = os.path.join(G.ENV.INPUT, \"CAPE-MPNN\", \"pdb_2021aug02\")\n",
    "\n",
    "NETMHCPAN_DIR_PATH = join(G.ENV.ARTEFACTS, \"eval\", \"immuno\", \"mhc_1\", \"netmhcpan\")\n",
    "if not os.path.exists(os.path.join(NETMHCPAN_DIR_PATH, 'definitions')):\n",
    "    os.symlink(\n",
    "        '../../../../../../data/input/immuno/mhc_1/Mhc1PredictorPwm/definitions',\n",
    "        os.path.join(NETMHCPAN_DIR_PATH, 'definitions')\n",
    "    )\n",
    "\n",
    "PEPTIDE_RANKS_DIR_PATH = os.path.join(os.environ['PF'], 'data', 'input', \"immuno\", \"mhc_1\", \"Mhc1PredictorPwm\", \"ranks\")\n",
    "PWM_PREDICTOR_TEST_RANKS_DIR_PATH = os.path.join(os.environ['PF'], 'data', 'input', \"immuno\", \"mhc_1\", \"Mhc1PredictorPwm\", \"ranks\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcfc0601-7af9-42b9-b550-b1008bba2e23",
   "metadata": {},
   "outputs": [],
   "source": [
    "DESTRESS_PROG_DIR_PATH = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96a209e4-801a-4ede-bc9d-416264900d83",
   "metadata": {},
   "outputs": [],
   "source": [
    "set_config_beam(PROTEIN_MPNN_REPO_PATH)\n",
    "CapeMPNN.base_model_pt_dir_path = os.path.join(G.ENV.INPUT, \"CAPE-MPNN\", \"vanilla_model_weights\")\n",
    "CapeMPNN.base_model_yaml_dir_path = os.path.join(G.ENV.INPUT, 'CAPE-MPNN', 'base_hparams')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "223328b3-a287-46f1-ab72-db6056baa1a2",
   "metadata": {},
   "source": [
    "## Eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3166478-5f99-4b13-9d7d-74903fe38b91",
   "metadata": {},
   "outputs": [],
   "source": [
    "MHC_1_PREDICTOR_EVAL = 'netmhcpan'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efbbd909-7b84-4b19-9fb2-5710ae5cc33a",
   "metadata": {},
   "outputs": [],
   "source": [
    "PLOT_MIN_SELF_KMER_LENGTH = [5, 6, 7]\n",
    "PLOT_NON_SELF_PROB_FACTORS = [0., 0.1, 0.5, 0.9, 0.99] #, 0.999]\n",
    "PLOT_MIN_TM_SCORE = 0.9"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c4ad135-79b3-4ba8-97e1-9d3df109a276",
   "metadata": {},
   "source": [
    "# Function definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a57d503-61ae-490c-bf44-27325dfda1d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_immuno_chains(source_id, protein_id, seq):\n",
    "    protein = proteins[protein_id]\n",
    "\n",
    "    chains = [c.replace(\"-\", \"X\") for c in seq.split('/')]\n",
    "    if protein.get_protein_type() != ProteinType.HETEROOLIGOMER:\n",
    "        if len(set(chains)) > 1:\n",
    "            print(f\"WARNING: {source_id} {protein_id}... {len(set(chains))} different chain seq\")\n",
    "        immuno_chains = chains[:1]\n",
    "    else:\n",
    "        immuno_chains = chains\n",
    "    return immuno_chains\n",
    "\n",
    "def get_possible_peptides(immuno_chains, lengths):\n",
    "    n = 0\n",
    "    for chain in immuno_chains:\n",
    "        for length in lengths:\n",
    "            n += max(len(chain) - length + 1, 0)\n",
    "    return n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fb56cc4-3618-4f1c-a1a7-22d82a4ec4f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_peers(pdb_id):\n",
    "    similar_proteins = get_similar_proteins(\n",
    "        pdb_id, PDB_DIR_PATH,\n",
    "        similar_max_score = SIMILAR_MAX_SCORE,\n",
    "        similar_min_score = SIMILAR_MIN_SCORE,\n",
    "        similar_min_tm_score = SIMILAR_MIN_TM_SCORE,\n",
    "        similar_max_count = SIMILAR_MAX_PROTEINS_CNT,\n",
    "        max_length_diff = SIMILAR_MAX_LENGTH_DIFF,\n",
    "        similar_proteins_dir_path = SIMILAR_PROTEINS_PATH,\n",
    "        server=PDB_SERVER\n",
    "    )\n",
    "    if len(similar_proteins) >= SIMILAR_MIN_PROTEINS_CNT:\n",
    "        return similar_proteins\n",
    "    else:\n",
    "        return {}\n",
    "\n",
    "\n",
    "def add_to_specific_proteins(liste, pdb_id, peer_groups, KEEP_CHAINS):\n",
    "    protein = None\n",
    "    if pdb_id not in liste:\n",
    "        exclude = False\n",
    "        for _pdb_id in liste:\n",
    "            if Levenshtein.distance(pdb_id, _pdb_id) <= 1:\n",
    "                exclude = True\n",
    "\n",
    "            if _pdb_id in peer_groups:\n",
    "                if pdb_id in peer_groups[_pdb_id]:\n",
    "                    exclude = True\n",
    "\n",
    "            if not exclude:\n",
    "                pdb_file_path = os.path.join(PDB_DIR_PATH, f\"{pdb_id}.pdb\")\n",
    "                protein = Protein.from_pdb(pdb_file_path, keep_chains=KEEP_CHAINS.get(pdb_id, None))\n",
    "                if MIN_SPECIFIC_CHAIN_LENGTH > len(list(protein.chains.values())[0]):\n",
    "                    exclude = True\n",
    "                elif np.sum([len(x) for x in protein.chains.values()]) > MAX_PROTEIN_LENGTH:\n",
    "                    exclude = True\n",
    "                elif includes_dna(os.path.join(PDB_DIR_PATH, f\"{pdb_id}.pdb\")):\n",
    "                    exclude = True\n",
    "                elif not check_xray(os.path.join(PDB_DIR_PATH, f\"{pdb_id}.pdb\")):\n",
    "                    exclude = True\n",
    "\n",
    "        if not exclude:\n",
    "            liste.append(pdb_id)\n",
    "        else:\n",
    "            protein = None\n",
    "            \n",
    "    return protein"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84b57809-f422-402a-a51b-60c99a0cf05a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_df_decodings(benchmark_sources, pdb_ids, min_self_kmer_lens, non_self_prob_factors, cape_beam_mhc_1_genotypes):\n",
    "    dfs = []\n",
    "\n",
    "    # add Benchmark rows\n",
    "    for benchmark_source_id, versions in benchmark_sources.items():\n",
    "        for version in versions:\n",
    "            df = pd.DataFrame(data=pdb_ids, columns=['protein_id'])\n",
    "            df['source_id'] = benchmark_source_id\n",
    "            for _col, _val in version.items():\n",
    "                df[_col] = _val\n",
    "            dfs.append(df)\n",
    "\n",
    "    # add CAPE-Beam rows\n",
    "    columns = ['checked_kmer_length', 'min_self_kmer_length', 'width', 'branching_factor', 'depth', 'tune_mhc_1_genotype', 'tune_mhc_1_predictor', 'eval_mhc_1_genotype', 'non_self_prob_factor']\n",
    "    for kmer_length in min_self_kmer_lens:\n",
    "        for non_self_prob_factor in non_self_prob_factors:\n",
    "            for mhc_1_genotype in cape_beam_mhc_1_genotypes:\n",
    "                df = pd.DataFrame(data=pdb_ids, columns=['protein_id'])\n",
    "    \n",
    "                if non_self_prob_factor is None:\n",
    "                    config = [kmer_length, kmer_length, 10, 1, kmer_length * 2, None, None, None, None]\n",
    "                else:\n",
    "                    config = [10, kmer_length, 10, 1, kmer_length * 2, mhc_1_genotype, MHC_1_PREDICTOR_DECODING, mhc_1_genotype, non_self_prob_factor]\n",
    "                    \n",
    "                set_df_cols_to(df, columns, config)\n",
    "    \n",
    "                df['proteome_file_name'] = PROTEOME_FILE_NAME\n",
    "                df['prune_min_acc_log_prob'] = -2000.\n",
    "                dfs.append(df)\n",
    "\n",
    "    df_result = pd.concat(dfs)\n",
    "    df_result.reset_index(inplace=True)\n",
    "\n",
    "    # add design properties columns\n",
    "    set_df_cols_to(\n",
    "        df_result,\n",
    "        ['seq_hash', 'seq', 'tm_data', 'kmers_not_in_proteome', 'kmers_presented', 'kmers_presented_pwm_dynamic', 'kmers_presented_netmhcpan', 'proportion', 'sampling_state'],\n",
    "        None\n",
    "    )\n",
    "    df_result['protein_type'] = df_result.apply(lambda row: protein_infos[row.protein_id][1], axis=1)\n",
    "    \n",
    "    # cast to integer\n",
    "    cast_df_cols_to(df_result, ['checked_kmer_length', 'min_self_kmer_length', 'width', 'branching_factor', 'depth'], int, -1)\n",
    "\n",
    "    return df_result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05f18171-d3bd-493f-bc71-5d74259825c5",
   "metadata": {},
   "source": [
    "## Sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa2a488f-849c-4431-8f33-5ffe69e4589a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_std(protein_id, pdb_input_file_path, protein_type, sampling_temp):\n",
    "    output_dir_path = join(FASTA_OUTPUT_PATH, protein_id, 'standard', str(sampling_temp))\n",
    "\n",
    "    fasta_output_file_path = join(output_dir_path, 'result.txt')\n",
    "    seed = 37\n",
    "    run_mpnn('v_48_020', \n",
    "             pdb_input_file_path, \n",
    "             fasta_output_file_path, \n",
    "             seed, \n",
    "             protein_type=protein_type,   \n",
    "             designed_positions=None, \n",
    "             sampling_temp=sampling_temp\n",
    "    )\n",
    "    seq = fasta_to_df(fasta_output_file_path).iloc[1].seq\n",
    "    str_to_file(seq, os.path.join(output_dir_path, 'beams.txt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6d3f591-027a-4ede-9278-2628a8cd0bef",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cape_mpnn_design_path(fasta_output_path, cape_mpnn_ckpt_id, protein_id, sampling_temp):\n",
    "    return join(fasta_output_path, protein_id, \"CAPE-MPNN\", str(sampling_temp), cape_mpnn_ckpt_id)\n",
    "    \n",
    "def get_cape_mpnn_fasta_file_path(fasta_output_path, cape_mpnn_ckpt_id, protein_id, seed, sampling_temp):\n",
    "    return join(get_cape_mpnn_design_path(fasta_output_path, cape_mpnn_ckpt_id, protein_id, sampling_temp), f\"{protein_id}_{seed}.fasta\")\n",
    "\n",
    "def generate_CAPE_MPNN(protein_id, pdb_input_file_path, fasta_output_path, sampling_temp, overwrite=False):\n",
    "    template_protein = proteins[protein_id]\n",
    "    protein_type = template_protein.get_protein_type()\n",
    "    template_seq = template_protein.get_seq()\n",
    "    \n",
    "    designed_positions = None\n",
    "\n",
    "    model_id, ckpt = CAPE_MPNN_CKPT_ID.split(':')\n",
    "\n",
    "    success = True\n",
    "    for trial in [1, 2, 3]:\n",
    "        seed = 36 + trial\n",
    "        fasta_output_file_path = get_cape_mpnn_fasta_file_path(fasta_output_path, CAPE_MPNN_CKPT_ID, protein_id, seed, sampling_temp)\n",
    "        if overwrite or not os.path.exists(fasta_output_file_path):\n",
    "            run_mpnn(\n",
    "                (os.path.join(CAPE_MPNN_WEIGHTS_PATH, model_id, 'ckpts'), ckpt),\n",
    "                pdb_input_file_path,\n",
    "                fasta_output_file_path,\n",
    "                seed,\n",
    "                protein_type=protein_type,\n",
    "                designed_positions=designed_positions,\n",
    "                sampling_temp=sampling_temp\n",
    "            )\n",
    "\n",
    "        if not os.path.exists(fasta_output_file_path):\n",
    "            print(f\"{ckpt_id:30s} {pdb_id} {trial} does not exist!\")\n",
    "            success = False\n",
    "        else:\n",
    "            seq = fasta_to_df(fasta_output_file_path).iloc[1].seq\n",
    "\n",
    "            assert len(seq) == len(template_seq)\n",
    "\n",
    "    if success:\n",
    "        source_design_dir_path = os.path.join(FASTA_OUTPUT_PATH, protein_id, \"CAPE-MPNN\")\n",
    "        design_file_path = os.path.join(source_design_dir_path, sampling_temp, CAPE_MPNN_CKPT_ID, 'beams.txt')\n",
    "        str_to_file(\"\", design_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "957ac81b-8b01-4cc0-8a86-c15f70df835a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_row_source_id(row):\n",
    "    if row.source_id not in benchmark_source_ids:\n",
    "        return get_source_id(\n",
    "            row.checked_kmer_length,\n",
    "            PROTEOME_FILE_NAME,\n",
    "            row.min_self_kmer_length,\n",
    "            row.tune_mhc_1_genotype,\n",
    "            immuno_predictor_setups[row.tune_mhc_1_predictor]['mhc_1'],\n",
    "            row.non_self_prob_factor,\n",
    "            row.width,\n",
    "            row.branching_factor,\n",
    "            row.depth,\n",
    "            row.prune_min_acc_log_prob\n",
    "        )        \n",
    "    return row.source_id\n",
    "\n",
    "\n",
    "def design_sequences(df_decodings, loch):\n",
    "    todo_cnt = 0\n",
    "    for i, row in tqdm(df_decodings.iterrows()):\n",
    "        source_id = get_row_source_id(row)\n",
    "        df_decodings.at[i, 'source_id'] = source_id\n",
    "        \n",
    "        source_design_dir_path = os.path.join(FASTA_OUTPUT_PATH, row.protein_id, source_id)\n",
    "        if source_id == 'standard':\n",
    "            design_file_path = os.path.join(source_design_dir_path, str(row.sampling_temp), 'beams.txt')\n",
    "        elif source_id == 'CAPE-MPNN':\n",
    "            design_file_path = os.path.join(source_design_dir_path, str(row.sampling_temp), CAPE_MPNN_CKPT_ID, 'beams.txt')\n",
    "        else:\n",
    "            design_file_path = os.path.join(source_design_dir_path, 'beams.txt')\n",
    "        exception_file_path = os.path.join(source_design_dir_path, 'exception.txt')\n",
    "\n",
    "        if not os.path.exists(design_file_path) and not os.path.exists(exception_file_path):\n",
    "            # pdb_input_file_path = os.path.join(PDB_DIR_PATH, f'{row.protein_id}.pdb')\n",
    "            pdb_input_file_path = loch.get_pdb_file_path(proteins[row.protein_id].seq_hash, predictor_structure_name='exp')\n",
    "\n",
    "            if source_id == 'standard':\n",
    "                sample_std(row.protein_id, pdb_input_file_path, row.protein_type, str(row.sampling_temp))\n",
    "            elif source_id == 'template':\n",
    "                str_to_file(proteins[row.protein_id].get_seq(), join(FASTA_OUTPUT_PATH, row.protein_id, 'template', 'beams.txt'))\n",
    "            elif source_id.startswith('CAPE-MPNN'):\n",
    "                generate_CAPE_MPNN(row.protein_id, pdb_input_file_path, FASTA_OUTPUT_PATH, str(row.sampling_temp))\n",
    "            elif source_id not in benchmark_source_ids:\n",
    "                command = [\"cape-beam.py\", \n",
    "                           '--pdb_input_file_path', pdb_input_file_path, '--protein_id', row.protein_id, '--protein_type', row.protein_type, \n",
    "                           '--output_dir_path', os.path.join(G.ENV.ARTEFACTS, 'designs'),\n",
    "                           '--proteome_file_name', row.proteome_file_name, '--min_self_kmer_length', row.min_self_kmer_length,\n",
    "                           '--checked_kmer_length', row.checked_kmer_length,\n",
    "                           '--width', row.width, '--depth', row.depth, '--branching_factor', row.branching_factor,\n",
    "                           '--prune_min_acc_log_prob', row.prune_min_acc_log_prob\n",
    "                ]\n",
    "                if row.tune_mhc_1_genotype is not None:\n",
    "                    command += [\n",
    "                        '--mhc_1_alleles', row.tune_mhc_1_genotype,\n",
    "                        '--mhc_1_predictor', row.tune_mhc_1_predictor,\n",
    "                        '--non_self_prob_factor', row.non_self_prob_factor                        \n",
    "                    ]\n",
    "                command = [str(c) for c in command]\n",
    "                print(f'# {source_id}')\n",
    "                print(' '.join(command))\n",
    "                todo_cnt += 1\n",
    "\n",
    "    print(f\"missing searches: {todo_cnt}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c56639bc-9dd3-4440-be0d-472a2ff8daaa",
   "metadata": {},
   "source": [
    "## Evaluate "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e86d06f-04b6-4a9a-bc9d-82cca8fe49b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_colabfold(df, loch, ignore_seq_hashes=None):\n",
    "    for i, row in tqdm(df.iterrows()):\n",
    "        source_id = get_row_source_id(row)\n",
    "\n",
    "        seqs = []\n",
    "        if source_id == 'template':\n",
    "            seqs.append(proteins[row.protein_id].get_seq())  \n",
    "        elif source_id.startswith('CAPE-MPNN'):\n",
    "            if row.seq_hash is not None and not isinstance(row.seq_hash, list):\n",
    "                seqs = None\n",
    "            else:\n",
    "                for trial in [1, 2, 3]:\n",
    "                    fasta_output_file_path = get_cape_mpnn_fasta_file_path(FASTA_OUTPUT_PATH, CAPE_MPNN_CKPT_ID, row.protein_id, 36 + trial, row.sampling_temp)\n",
    "                    seq = fasta_to_df(fasta_output_file_path).iloc[1].seq\n",
    "                    seqs.append(seq)\n",
    "        else:\n",
    "            if source_id == \"standard\":\n",
    "                source_design_dir_path = os.path.join(FASTA_OUTPUT_PATH, row.protein_id, source_id, str(row.sampling_temp))\n",
    "            else:\n",
    "                source_design_dir_path = os.path.join(FASTA_OUTPUT_PATH, row.protein_id, source_id)             \n",
    "                \n",
    "            design_file_path = os.path.join(source_design_dir_path, 'beams.txt')\n",
    "            exception_file_path = os.path.join(source_design_dir_path, 'exception.txt')\n",
    "\n",
    "            if os.path.exists(exception_file_path):\n",
    "                df.at[i, 'seq_hash'] = None\n",
    "                df.at[i, 'seq'] = None\n",
    "                continue\n",
    "            elif os.path.exists(design_file_path):\n",
    "                seqs.append(file_to_str(design_file_path).split('\\n')[0])\n",
    "\n",
    "\n",
    "        if seqs is not None:\n",
    "            seq_hashes = []\n",
    "            for seq in seqs:\n",
    "                # add to loch\n",
    "                seq_hashes.append(seq_hash := loch.add_seq(seq))\n",
    "\n",
    "                if seq_hash not in ignore_seq_hashes:\n",
    "                    # copy to the colabfold path\n",
    "                    cp_fasta_to_dir(seq_hash, os.path.join(COLABFOLD_PATH, 'input'), translate=(\"/-\", \":X\", \"\"))\n",
    "                else:\n",
    "                    print(f\"Ignore: {row.source_id} {row.protein_id}\")\n",
    "    \n",
    "            df.at[i, 'seq'] = seqs\n",
    "            df.at[i, 'seq_hash'] = seq_hashes\n",
    "\n",
    "\n",
    "def from_colabfold(df_decodings, loch):\n",
    "    COLABFOLD_OUTPUT_PATH = os.path.join(COLABFOLD_PATH, 'output')\n",
    "    for i, row in tqdm(df_decodings.iterrows()):\n",
    "        seq_hashes = row.seq_hash\n",
    "        if not isinstance(row.seq_hash, list):\n",
    "            seq_hashes = [row.seq_hash]\n",
    "            \n",
    "        for seq_hash in seq_hashes:\n",
    "            target_file_path = loch.get_pdb_file_path(seq_hash, predictor_structure_name='AF')\n",
    "            if not os.path.exists(target_file_path):\n",
    "                files = get_entries(os.path.join(COLABFOLD_OUTPUT_PATH), f\"{seq_hash}_relaxed_rank_001_.+\\.pdb\")\n",
    "                if len(files) == 1:\n",
    "                    for file_name, file_paths in files.items():                        \n",
    "                        shutil.copy(os.path.join(COLABFOLD_OUTPUT_PATH, file_name), target_file_path)\n",
    "                if len(files) > 1:\n",
    "                    raise Error()\n",
    "\n",
    "        if isinstance(row.seq_hash, list) and len(row.seq_hash) == 1:\n",
    "            df_decodings.at[i, 'seq'] = row.seq[0]\n",
    "            df_decodings.at[i, 'seq_hash'] = row.seq_hash[0]\n",
    "           \n",
    "\n",
    "def add_tm_data(df_decodings, loch, overwrite=False):\n",
    "    for i, row in tqdm(df_decodings.iterrows()):\n",
    "        if row.tm_data is None or overwrite:\n",
    "            source_id = get_row_source_id(row)\n",
    "            source_design_dir_path = os.path.join(FASTA_OUTPUT_PATH, row.protein_id, source_id)\n",
    "            design_file_path = os.path.join(source_design_dir_path, 'beams.txt')\n",
    "            exception_file_path = os.path.join(source_design_dir_path, 'exception.txt')\n",
    "    \n",
    "            if row.seq_hash is not None:\n",
    "                predictor_structure_name = 'exp' if row.source_id == 'template' else 'AF'\n",
    "                source_pdb_file_path = loch.get_pdb_file_path(row.seq_hash, predictor_structure_name=predictor_structure_name)\n",
    "\n",
    "                if os.path.exists(source_pdb_file_path):\n",
    "                # source_pdb_file_path = list(get_entries(os.path.join(COLABFOLD_PATH, 'output'), fr\"{row.seq_hash}_relaxed_rank_001_.+\\.pdb\", subdirs=False).values())\n",
    "                # if len(source_pdb_file_path) > 0:\n",
    "                #     source_pdb_file_path = source_pdb_file_path[0][0]\n",
    "                    template_pdb_file_path = os.path.join(PDB_DIR_PATH, f'{row.protein_id}.pdb')    \n",
    "                    df_decodings.at[i, 'tm_data'] =  align_structures(template_pdb_file_path, source_pdb_file_path)\n",
    "\n",
    "def kmers_in_proteome(seq, proteome_tree, length):\n",
    "    in_proteome = []\n",
    "    not_in_proteome = []\n",
    "    kmers = get_kmers(seq, length, check_aa=False)\n",
    "\n",
    "    for kmer in kmers:\n",
    "        if proteome_tree.get_kmer(kmer) is None:\n",
    "            not_in_proteome.append(kmer)\n",
    "        else:\n",
    "            in_proteome.append(kmer)\n",
    "    return in_proteome, not_in_proteome\n",
    "\n",
    "\n",
    "def analyse_kmers_non_human(seq, proteome_tree, max_checked_kmer_length=10):\n",
    "    kmers = get_kmers(seq, list(range(1, max_checked_kmer_length+1)))\n",
    "    non_human = []\n",
    "    for kmer in kmers:\n",
    "        if not proteome_tree.has_kmer(kmer):\n",
    "            non_human.append(kmer)\n",
    "\n",
    "    return non_human\n",
    "    \n",
    "\n",
    "def analyse_kmers_presented(seq, immuno_setup=None, predictor_setup=None, max_checked_kmer_length=10):\n",
    "    kmers = get_kmers(seq, list(range(1, max_checked_kmer_length+1)))\n",
    "    kmers = [kmer for kmer in kmers if len(kmer) in MHC_1_PEPTIDE_LENGTHS]\n",
    "\n",
    "    presented = []\n",
    "    if not immuno_setup is None:\n",
    "        predictor_setup['mhc_1'].predict_peptides(kmers, immuno_setup['mhc_1'])\n",
    "        for kmer in kmers:\n",
    "            if predictor_setup['mhc_1'].peptide_presented(kmer, immuno_setup['mhc_1']):\n",
    "                presented.append(kmer)\n",
    "\n",
    "    return presented\n",
    "    \n",
    "\n",
    "def analyse_kmer(df_decodings, source_id=None, overwrite=False):\n",
    "    if 'immuno_chains' not in df_decodings:\n",
    "        df_decodings['immuno_chains'] = None\n",
    "        \n",
    "    for i, row in tqdm(df_decodings.iterrows()):\n",
    "        immuno_chains = None\n",
    "        if row.seq is not None and isinstance(row.seq, str):\n",
    "            immuno_chains = get_immuno_chains(row.source_id, row.protein_id, row.seq)\n",
    "            \n",
    "            for col in ['kmers_not_in_proteome', 'kmers_presented'] + [f'kmers_presented_{predictor_postfix}' for predictor_postfix in immuno_predictor_setups.keys()]:\n",
    "                if col not in df_decodings.columns:\n",
    "                    df_decodings[col] = None\n",
    "            \n",
    "            for predictor_postfix, predictor_setup in immuno_predictor_setups.items():            \n",
    "                if df_decodings.at[i, f'kmers_presented_{predictor_postfix}'] is None or overwrite:\n",
    "                    df_decodings.at[i, f'kmers_presented_{predictor_postfix}'] = []\n",
    "                    for chain in immuno_chains:\n",
    "                        df_decodings.at[i, f'kmers_presented_{predictor_postfix}'] += analyse_kmers_presented(\n",
    "                            chain, \n",
    "                            immuno_setup={'mhc_1': row.eval_mhc_1_genotype}, \n",
    "                            predictor_setup=predictor_setup, \n",
    "                            max_checked_kmer_length=10\n",
    "                        )\n",
    "            \n",
    "            if df_decodings.at[i, 'kmers_not_in_proteome'] is None or overwrite:\n",
    "                df_decodings.at[i, 'kmers_not_in_proteome'] = []\n",
    "                for chain in immuno_chains:\n",
    "                    df_decodings.at[i, 'kmers_not_in_proteome'] += analyse_kmers_non_human(chain, proteome_tree, max_checked_kmer_length=10)    \n",
    "                \n",
    "            for prop_len in [5, 6, 7, 8, 9, 10]:\n",
    "                in_proteome = []\n",
    "                not_in_proteome = []\n",
    "                for chain in immuno_chains:\n",
    "                    _in_proteome, _not_in_proteome = kmers_in_proteome(chain, proteome_tree, prop_len)\n",
    "                    in_proteome += _in_proteome\n",
    "                    not_in_proteome += _not_in_proteome\n",
    "                df_decodings.at[i, f'proportion_{prop_len}'] = len(in_proteome) / max(len(in_proteome) + len(not_in_proteome), 1.)\n",
    "                \n",
    "        df_decodings.at[i, 'kmers_presented'] = None\n",
    "        df_decodings.at[i, 'immuno_chains'] = immuno_chains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7bf44d0-0f91-47c2-8dec-50204529dc7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_TM_data(seq_hash_data, seq_hash_generated, loch):\n",
    "    data_pdb_file_path = loch.get_pdb_file_path(seq_hash_data, predictor_structure_name=\"exp\")\n",
    "    generated_pdb_file_path = loch.get_pdb_file_path(seq_hash_generated)\n",
    "\n",
    "    if os.path.exists(data_pdb_file_path) and os.path.exists(generated_pdb_file_path):\n",
    "        tm_score, tm_alignment_length, tm_rmsd, tm_identical, len_chain_1, len_chain_2 = align_structures(\n",
    "            data_pdb_file_path, generated_pdb_file_path, return_chain_lengths=True)\n",
    "        result = (tm_score, tm_alignment_length, tm_rmsd, tm_identical, len_chain_1, len_chain_2)\n",
    "    else:\n",
    "        result = None\n",
    "\n",
    "    return result\n",
    "\n",
    "\n",
    "def add_cape_mpnn_designs(df, cape_mpnn_ckpt_id, loch):\n",
    "    for idx, row in df.iterrows():\n",
    "        old_row_seq_hash = row.seq_hash\n",
    "            \n",
    "        if row.source_id.startswith('CAPE-MPNN'):\n",
    "            if isinstance(row.seq_hash, list):\n",
    "                cape_mpnn_design_file_path = os.path.join(get_cape_mpnn_design_path(FASTA_OUTPUT_PATH, cape_mpnn_ckpt_id, row.protein_id, row.sampling_temp), \"beams.txt\")\n",
    "                best_seq = file_to_str(cape_mpnn_design_file_path)\n",
    "\n",
    "                protein_id = row.protein_id\n",
    "                seq_hash_data = get_seq_hash(proteins[protein_id].get_seq())\n",
    "                if len(best_seq) == 0:  # and row.seq_hash is None:\n",
    "                \n",
    "                    max_tm_seq_hash = None\n",
    "                    max_tm_score, max_tm_data = -1., None\n",
    "                    max_tm_kmers_not_in_proteome, max_tm_kmers_presented_netmhcpan = None, None\n",
    "                    min_vis_seq_hash = None\n",
    "                    min_vis_tm_score, min_vis_tm_data = None, None\n",
    "                    min_vis_kmers_not_in_proteome, min_vis_kmers_presented_netmhcpan = None, None\n",
    "                    min_vis_mhc_1 = None\n",
    "                    \n",
    "                    seqs = {}\n",
    "                    for trial in [1, 2, 3]:\n",
    "                        cape_mpnn_fasta_file_path = get_cape_mpnn_fasta_file_path(FASTA_OUTPUT_PATH, CAPE_MPNN_CKPT_ID, protein_id, 36 + trial, row.sampling_temp)\n",
    "        \n",
    "                        seq = fasta_to_df(cape_mpnn_fasta_file_path).iloc[1].seq\n",
    "                        seq_hash = get_seq_hash(seq)\n",
    "                        seqs[seq_hash] = seq\n",
    "        \n",
    "                        _df = pd.DataFrame({'protein_id': [protein_id], 'seq': [seq], 'source_id': ['CAPE-MPNN'], 'eval_mhc_1_genotype': [row.eval_mhc_1_genotype]})\n",
    "                        analyse_kmer(_df, cape_mpnn_ckpt_id)\n",
    "                        kmers_presented_netmhcpan = _df.iloc[0].kmers_presented_netmhcpan\n",
    "                        kmers_not_in_proteome = _df.iloc[0].kmers_not_in_proteome\n",
    "                            \n",
    "                        vis_mhc_1 = len(kmers_presented_netmhcpan)\n",
    "            \n",
    "                        pdb_file_path = loch.get_pdb_file_path(seq_hash, predictor_structure_name='AF')\n",
    "                        print(pdb_file_path)\n",
    "                        if os.path.exists(pdb_file_path):\n",
    "                            tm_data = calc_TM_data(seq_hash_data, seq_hash, loch)\n",
    "                            tm_score = tm_data[0]\n",
    "            \n",
    "                            if tm_score is not None and tm_score > max_tm_score:\n",
    "                                max_tm_seq_hash = seq_hash\n",
    "                                max_tm_score, max_tm_data = tm_score, tm_data\n",
    "                                max_tm_kmers_not_in_proteome, max_tm_kmers_presented_netmhcpan = kmers_not_in_proteome, kmers_presented_netmhcpan\n",
    "            \n",
    "                                if tm_score >= 0.9:\n",
    "                                    if min_vis_mhc_1 is None or min_vis_mhc_1 > vis_mhc_1:\n",
    "                                        min_vis_seq_hash = seq_hash\n",
    "                                        min_vis_tm_score, min_vis_tm_data = tm_score, tm_data\n",
    "                                        min_vis_kmers_not_in_proteome, min_vis_kmers_presented_netmhcpan = kmers_not_in_proteome, kmers_presented_netmhcpan\n",
    "                                        \n",
    "                                        min_vis_mhc_1 = vis_mhc_1\n",
    "                            print(f'{protein_id} {trial} exists tm-score: {tm_score} vis_mhc_1: {vis_mhc_1}')\n",
    "            \n",
    "                    if min_vis_seq_hash is None:\n",
    "                        best_seq_hash = max_tm_seq_hash\n",
    "                        best_tm_score, best_tm_data = max_tm_score, max_tm_data\n",
    "                        best_kmers_not_in_proteome, best_kmers_presented_netmhcpan = max_tm_kmers_not_in_proteome, max_tm_kmers_presented_netmhcpan\n",
    "                    else:\n",
    "                        best_seq_hash = min_vis_seq_hash\n",
    "                        best_tm_score, best_tm_data = min_vis_tm_score, min_vis_tm_data\n",
    "                        best_kmers_not_in_proteome, best_kmers_presented_netmhcpan = min_vis_kmers_not_in_proteome, min_vis_kmers_presented_netmhcpan\n",
    "    \n",
    "                    best_seq = seqs[best_seq_hash]\n",
    "                    str_to_file(best_seq, cape_mpnn_design_file_path)\n",
    "                else:\n",
    "                    best_seq_hash = get_seq_hash(best_seq)\n",
    "                    best_tm_data = calc_TM_data(seq_hash_data, best_seq_hash, loch)\n",
    "                    _df = pd.DataFrame({'protein_id': [protein_id], 'seq': [best_seq], 'source_id': ['CAPE-MPNN'], 'eval_mhc_1_genotype': [row.eval_mhc_1_genotype]})\n",
    "                    analyse_kmer(_df, cape_mpnn_ckpt_id)\n",
    "                    best_kmers_presented_netmhcpan = _df.iloc[0].kmers_presented_netmhcpan\n",
    "                    best_kmers_not_in_proteome = _df.iloc[0].kmers_not_in_proteome\n",
    "\n",
    "\n",
    "                df.at[idx, 'seq_hash'] = best_seq_hash\n",
    "                df.at[idx, 'seq'] = best_seq\n",
    "                df.at[idx, 'tm_data'] = best_tm_data\n",
    "                df.at[idx, 'kmers_not_in_proteome'] = best_kmers_not_in_proteome\n",
    "                df.at[idx, 'kmers_presented_netmhcpan'] = best_kmers_presented_netmhcpan\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1413d1f7-ef79-41a4-b9db-c9fe7888e0bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_deimmunized(df, show=True):\n",
    "    problems = []\n",
    "    not_checked = []\n",
    "    for idx, row in df.query('not seq_hash.isnull()').iterrows():\n",
    "        if row.source_id not in benchmark_source_ids:\n",
    "            if row.checked_kmer_length >= 10:\n",
    "                problematic = len([x for x in row.kmers_presented_pwm_dynamic if x in row.kmers_not_in_proteome])\n",
    "                if show:\n",
    "                    print(f\"{row.source_id} {row.protein_id} {row.checked_kmer_length} {len(row.kmers_presented_pwm_dynamic)} vs. {len(row.kmers_presented_netmhcpan)} - {problematic}\")\n",
    "                if problematic > 0:\n",
    "                    problems.append(row)\n",
    "            else:\n",
    "                not_checked.append(row.source_id)\n",
    "    \n",
    "    assert len(problems) == 0\n",
    "    \n",
    "    print(f\"The following CAPE-Beam IDs were not checked: {not_checked}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6dd2114-c5d7-43b8-8a48-db4448a1da1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_between(v, a, b):\n",
    "    lower_check = (a is None) or (a <= v)\n",
    "    upper_check = (b is None) or (v <= b)\n",
    "    return lower_check and upper_check"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f3260ad-9d3e-42d5-9d8d-32bf6be56e7b",
   "metadata": {},
   "source": [
    "## Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7216978-fb61-41f0-aaff-b7fe3d405184",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_Beam_source_ids(min_self_kmer_lengths, non_self_prob_factors, tune_mhc_1_genotype):\n",
    "    result = []\n",
    "    for _min_self_kmer_length in min_self_kmer_lengths:\n",
    "        for _non_self_prob_factor in non_self_prob_factors:\n",
    "            result.append(get_source_id(\n",
    "                checked_kmer_length=10, \n",
    "                proteome_file_name=PROTEOME_FILE_NAME, \n",
    "                min_self_kmer_length=_min_self_kmer_length, \n",
    "                tune_mhc_1_genotype=tune_mhc_1_genotype, \n",
    "                tune_mhc_1_predictor=immuno_predictor_setups[MHC_1_PREDICTOR_DECODING]['mhc_1'], \n",
    "                non_self_prob_factor=_non_self_prob_factor, \n",
    "                width=10, \n",
    "                branching_factor=1, \n",
    "                depth=_min_self_kmer_length*2, \n",
    "                prune_min_acc_log_prob=-2000.\n",
    "            ))\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6a5ea10-b253-4a9e-80bd-c121acbe8303",
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_kmers_presented(df, mhc_1_predictor_name):\n",
    "    df['kmers_presented'] = df.apply(lambda row: row[f'kmers_presented_{mhc_1_predictor_name}'], axis=1)    \n",
    "\n",
    "def get_df_plot(df):\n",
    "    df_plot = df.copy()\n",
    "    df_plot['seq_len'] = df_plot.apply(lambda row: len(row.seq) if row.seq is not None else 0, axis=1)\n",
    "\n",
    "    set_kmers_presented(df_plot, MHC_1_PREDICTOR_EVAL)\n",
    "\n",
    "    df_plot['kmers_presented_not_in_proteome'] = df_plot.apply(\n",
    "        lambda row: set(row.kmers_presented) & set(row.kmers_not_in_proteome) if row.seq_len > 0 else None, \n",
    "        axis=1\n",
    "    )\n",
    "\n",
    "    for c in ['not_in_proteome', 'presented', 'presented_not_in_proteome']:\n",
    "        df_plot[c] = df_plot.apply(lambda row: len(row[f'kmers_{c}']) if row.seq_len > 0 else None, axis=1)\n",
    "        # df_plot[c] = df_plot.apply(lambda row: len(row[f'kmers_{c}']) if row[f'kmers_{c}'] is not None else None, axis=1)\n",
    "    \n",
    "    df_plot['tm_aligned'] = df_plot.apply(lambda row: row.tm_data[1]/len(row.seq.split(\"/\")[0]) if row.tm_data is not None and row.seq_len is not None else None, axis=1)\n",
    "    df_plot['tm_score'] = df_plot.apply(lambda row: row.tm_data[0] if row.tm_data is not None else None, axis=1)\n",
    "\n",
    "    df_plot['presented_not_in_proteome_pc'] = df_plot.apply(lambda r: r.presented_not_in_proteome/get_possible_peptides(r.immuno_chains, [8, 9, 10]) if r.seq_len > 0 else None, axis=1)\n",
    "\n",
    "    df_plot['seq_hash'] = df_plot.apply(lambda r: r.seq_hash if isinstance(r.seq_hash, str) else None, axis=1)\n",
    "\n",
    "    return df_plot.query(\"not seq_hash.isnull()\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f187521e-0a22-41ea-8b46-aa7f64bcba71",
   "metadata": {},
   "source": [
    "### Plot fig X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9837fb93-cf94-4f6d-b33d-c2236e52020e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_successful_source_ids(df, min_tm_score):\n",
    "    source_ids = list(df.sort_values(['min_self_kmer_length', 'non_self_prob_factor'], ascending=[True, False]).source_id.unique())\n",
    "    result = []\n",
    "    for source_id in source_ids:\n",
    "        if len(df.query(f'tm_score >= {min_tm_score} and source_id == \"{source_id}\"')) > 0:\n",
    "            result.append(source_id)\n",
    "    return result\n",
    "    \n",
    "\n",
    "def fig_X(df, source_ids, rename_source_ids, palette_source_id, min_tm_score=None, \n",
    "          homo_sapiens_proteins=None,\n",
    "          sources_horizontal=True, kmer_lengths=[5,6,7,8,9,10], \n",
    "          hspace=.1, wspace=0.15, groupseps=[], fig_height=0.8, label_fontsize=8):     \n",
    "    infos = {\n",
    "        'tm_score': ('TM score', (0., 1.2), 'linear', \".2f\", False),\n",
    "        'proportion': (\"self-kmers \\n [frac of kmers]\", (0.01, 5.), 'log', \".0%\", True),\n",
    "        # 'presented_not_in_proteome_pc': (\"presented 8-10mers \\n not in proteome \\n [frac of 8-10mers]\", (0.001, 0.2), 'log', \".1%\", True),\n",
    "        'presented_not_in_proteome_pc': (\"presented \\n non-self 8-10mers \\n [frac of 8-10mers]\", (0.001, 0.2), 'log', \".1%\", True),\n",
    "        'rosetta p.a.': ('rosetta score \\n [REU per AA]', (None, 2.), 'linear', \".1f\", False),\n",
    "        'delta isoelectric point': ('$\\Delta$ pI', (None, None), 'linear', \".1f\", False),\n",
    "        'aggrescan3d max': ('aggrescan3d max', (None, None), 'linear', \".1f\", False)\n",
    "    }\n",
    "    _palette = None\n",
    "   \n",
    "    n_rows, n_cols = (len(infos), 1) if sources_horizontal else (1, len(infos))\n",
    "\n",
    "    \n",
    "    fig = plt.figure(figsize=(A4_width, A4_height*fig_height))\n",
    "    gs = gridspec.GridSpec(n_rows, n_cols, width_ratios=[1]*n_cols, hspace=hspace, wspace=wspace)\n",
    "  \n",
    "    for j, (info_col, info_details) in enumerate(infos.items()):\n",
    "        info_name, info_range, info_scale, format_median, ignore_human_proteins = info_details\n",
    "        \n",
    "        ax = fig.add_subplot(gs[j, 0] if sources_horizontal else gs[0, j])\n",
    "        x_col, y_col = ('source_id', info_col) if sources_horizontal else (info_col, 'source_id')\n",
    "        axline = ax.axhline if sources_horizontal else ax.axvline\n",
    "        \n",
    "        _df = df\n",
    "        if info_col != 'tm_score' and min_tm_score is not None:\n",
    "            _df = df.query(f'tm_score >= {min_tm_score}')\n",
    "\n",
    "        if ignore_human_proteins:\n",
    "            _df = _df.query(f\"protein_id not in {homo_sapiens_proteins}\")\n",
    "        \n",
    "        if info_col not in ['proportion']:\n",
    "            sns.boxplot(_df, x=x_col, y=y_col, palette=palette_source_id, order=source_ids, ax=ax, width=0.8)\n",
    "            if info_col == 'rosetta p.a.':\n",
    "                axline(y=-1, color='grey', linestyle='--', alpha=0.5) \n",
    "        elif info_col == 'proportion':\n",
    "            # get one line per proportion and kmer_len\n",
    "            _df_melted = pd.melt(_df, id_vars=['source_id'], value_vars=[f'proportion_{k}' for k in range(5, 11)]).rename(columns={'variable': 'kmer_len', 'value': info_col})\n",
    "            _df_melted['kmer_len'] = _df_melted.apply(lambda r: r.kmer_len.split('_')[1], axis=1)\n",
    "\n",
    "            # extend the color palette\n",
    "            tmp = glasbey.extend_palette(list(palette_source_id.values()), palette_size=len(palette_source_id) + len(kmer_lengths), lightness_bounds=(0, 50))\n",
    "            _palette = {str(k): tmp[i] for i, k in enumerate(list(palette_source_id.keys()) + kmer_lengths)}\n",
    "\n",
    "            # plot the proportions of each source\n",
    "            sns.boxplot(_df_melted, x=x_col, y=y_col, hue='kmer_len', order=source_ids, palette=_palette, ax=ax, flierprops=dict(marker='o', markersize=1.5))\n",
    "\n",
    "            # Add horizontal lines for the human genome background distribution\n",
    "            for kmer_len, row in df_pc_human.iterrows():\n",
    "                axline(y=row.human, color=_palette[str(kmer_len)], linestyle='--', alpha=0.5, label=f'Mean kmer_len={kmer_len}')\n",
    "        \n",
    "            plot_legend_patches(\n",
    "                {k: v for k, v in _palette.items() if k in [str(k) for k in kmer_lengths]}, \n",
    "                ax, \n",
    "                location='center', \n",
    "                ncol=len(kmer_lengths), plain=False, frameon=False,\n",
    "                legend_kwargs={'bbox_to_anchor': (0.5, 0.92), 'fontsize': 8}\n",
    "            )\n",
    "\n",
    "        if format_median is not None:\n",
    "            sub_info_cols, fontstyle = [info_col], {'fontweight': 'bold', 'color': 'black'}\n",
    "            if info_col == 'proportion':\n",
    "                sub_info_cols = [f'proportion_{k}' for k in kmer_lengths]\n",
    "                fontstyle = {'fontsize': 7}\n",
    "            \n",
    "            d = 1./len(sub_info_cols)\n",
    "            rotation = 0 if len(sub_info_cols) == 1 else 90\n",
    "            \n",
    "            for s, source_id in enumerate(source_ids):                \n",
    "                for c, _info_col in enumerate(sub_info_cols):\n",
    "                    v = float(_df.query(f\"source_id == '{source_id}'\")[[_info_col]].median().iloc[0])\n",
    "                    \n",
    "                    p1 = s + d * (c - (len(sub_info_cols)-1)/2)*0.8\n",
    "                    p2 = v if info_range[0] is None else max(v, info_range[0])\n",
    "                    p2 = p2 if info_range[1] is None else min(p2, info_range[1])\n",
    "\n",
    "                    if info_col == 'proportion':\n",
    "                        fontstyle.update({'color': _palette[str(kmer_lengths[c])]})\n",
    "\n",
    "                    if is_between(v, info_range[0], info_range[1]):                    \n",
    "                        #x, y, va, ha = (s, v, 'top', 'center') if sources_horizontal else (s, v, 'center', 'right')\n",
    "                        x, y, va, ha = (p1, p2, 'center', 'center') if sources_horizontal else (p2, p1, 'center', 'center')\n",
    "                        ax.text(x=x, y=y, s=f'{v:{format_median}}', verticalalignment=va, horizontalalignment=ha, \n",
    "                                rotation=rotation, **fontstyle,\n",
    "                                bbox=dict(facecolor=\"white\", alpha=0.7, edgecolor=\"none\", boxstyle=\"round,pad=0.05\")\n",
    "                        )\n",
    "        \n",
    "        labels = []\n",
    "        if sources_horizontal:\n",
    "            ax.set_ylim(info_range)\n",
    "            get_ticklabels, set_ticklabels = ax.get_xticklabels, ax.set_xticklabels\n",
    "            ax.set_xlabel('')\n",
    "            ax.set_ylabel(info_name, fontsize=label_fontsize)\n",
    "            ax.set_yscale(info_scale)\n",
    "        else:\n",
    "            ax.set_xlim(info_range)\n",
    "            get_ticklabels, set_ticklabels = ax.get_yticklabels, ax.set_yticklabels\n",
    "            ax.set_xlabel(info_name, fontsize=label_fontsize)\n",
    "            ax.set_ylabel('')\n",
    "            ax.set_xscale(info_scale)\n",
    "        \n",
    "        if j == len(infos) - 1:\n",
    "            for ticklabel in get_ticklabels():\n",
    "                source_id = ticklabel.get_text()\n",
    "                n_designs = len(df.query(f\"source_id == '{source_id}'\" + (\"\" if min_tm_score is None else f\" and tm_score >= {min_tm_score}\") ))\n",
    "                labels.append(f\"{rename_source_ids.get(source_id, source_id)}\\n N={n_designs}\")\n",
    "        \n",
    "        set_ticklabels(labels, rotation=50, fontsize=label_fontsize)\n",
    "\n",
    "        # add separating lines between sources\n",
    "        for s, source_id in enumerate(source_ids):\n",
    "            if s not in groupseps:\n",
    "                ax.axvline(x=s+0.5, linestyle='--', color='lightgrey')\n",
    "            else:\n",
    "                ax.axvline(x=s+0.5, linestyle='-', color='grey')\n",
    "\n",
    "        # add figure ids\n",
    "        x_offset, y_offset = (-0.15, 1.) if sources_horizontal else (1., -0.15)\n",
    "        ax.text(x_offset, y_offset, f\"{string.ascii_lowercase[j]})\", transform=ax.transAxes, fontsize=label_fontsize*1.25, fontweight='bold', va='top', ha='right')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "403a5cf3-c447-426a-83fb-aefbe36cff6b",
   "metadata": {},
   "source": [
    "### Plot fig A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "479af699-ae5f-4faa-afeb-78e6e35e6cb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_fig_A(df, palette_source_id, area=None, rename_source_ids=None, x_lim_pnip=None, min_tm_score=None, show_x_labels=True):\n",
    "    df = df.copy()\n",
    "\n",
    "    # df['pnip'] = df.apply(lambda r: r.presented_not_in_proteome/(len(r.seq)*3 - 24), axis=1)\n",
    "    df['pnip'] = df.apply(lambda r: r.presented_not_in_proteome/get_possible_peptides(r.immuno_chains, [8, 9, 10]), axis=1)\n",
    "    source_ids = list(df.source_id.unique())\n",
    "\n",
    "    x_lim_pnip = df.pnip.max() + 0.1 if x_lim_pnip is None else x_lim_pnip\n",
    "  \n",
    "\n",
    "    if area is None:\n",
    "        fig = plt.figure(figsize=(A4_width, A4_height/2))\n",
    "        gs = gridspec.GridSpec(len(source_ids), \n",
    "                               3,\n",
    "                               width_ratios=[1, 1, 1],\n",
    "                               hspace=.5,\n",
    "                               wspace=0.15,\n",
    "                              )\n",
    "    else:\n",
    "        fig = plt.gcf()\n",
    "        gs = area.subgridspec(len(source_ids), \n",
    "                               3,\n",
    "                               width_ratios=[1, 1, 1],\n",
    "                               hspace=.5,\n",
    "                               wspace=0.15,\n",
    "                              )\n",
    "\n",
    "    axes = np.full((len(source_ids), 3), None, dtype=object)\n",
    "    _lens = [5, 6, 7, 8, 9, 10]\n",
    "\n",
    "    for i, source_id in enumerate(source_ids):\n",
    "        source_name = rename_source_ids[source_id] if (rename_source_ids is not None and source_id in rename_source_ids) else source_id\n",
    "        \n",
    "        _df = df.query(f'source_id == \"{source_id}\"')\n",
    "        \n",
    "        ax_0 = fig.add_subplot(gs[i, 0])  #, sharey=axes[0, 0])\n",
    "        axes[i, 0] = ax_0\n",
    "\n",
    "        #\n",
    "        # TM scores\n",
    "        #\n",
    "        \n",
    "        sns.boxplot(_df, y='source_id', x='tm_score', hue='source_id', palette=palette_source_id, ax=ax_0)\n",
    "       \n",
    "        ax_0.tick_params(axis='y', labeltop=True, labelbottom=False) \n",
    "        ax_0.get_legend().remove()\n",
    "\n",
    "        ax_0.set_ylabel('')\n",
    "        ax_0.set_xlabel('')\n",
    "        ax_0.set_xlim((0., 1.))\n",
    "\n",
    "\n",
    "        if min_tm_score is not None:\n",
    "            _df = _df.query(f\"tm_score >= {min_tm_score}\")\n",
    "        N = len(_df)\n",
    "                \n",
    "        labels = [f\"{source_name}\\nN={N}\"]\n",
    "        ax_0.set_yticklabels(labels)\n",
    "        ax_0.xaxis.set_ticks_position('top')\n",
    "        ax_0.xaxis.set_label_position('top')\n",
    "        if i != 0 or not show_x_labels:\n",
    "            ax_0.set_xticklabels([])\n",
    "        else:\n",
    "            ax_0.set_xlabel('TM score')\n",
    "        \n",
    "        if N == 0:\n",
    "            continue\n",
    "        #\n",
    "        # self kmer proportions\n",
    "        #\n",
    "\n",
    "        \n",
    "        ax_1 = fig.add_subplot(gs[i, 1])  #, sharey=axes[1, 0])\n",
    "        axes[i, 1] = ax_1            \n",
    "                  \n",
    "        df_h = pd.DataFrame(_df[[f'proportion_{l}' for l in _lens]].mean())\n",
    "        df_h.columns = ['pc']\n",
    "        df_h['len'] = df_h.apply(lambda r: int(r.name.split('_')[1]), axis=1)\n",
    "        sns.scatterplot(df_h, x='len', y='pc', color=palette_source_id[source_id], ax=ax_1)\n",
    "\n",
    "        j = 1\n",
    "        for _, row in df_h.sort_values('len').iterrows():\n",
    "            if j < len(df_h):  # right of dat\n",
    "                v = 3 if row['pc'] < .5 else -3\n",
    "                ax_1.annotate(f'{row[\"pc\"]:.2f}', (row['len'], row['pc']), \n",
    "                          xytext=(3, v), textcoords='offset points', ha='left', va='center', fontsize=7)\n",
    "            else:  # above dot\n",
    "                v = 3 if row['pc'] < .5 else -3\n",
    "                ax_1.annotate(f'{row[\"pc\"]:.2f}', (row['len'], row['pc']), \n",
    "                          xytext=(0, v), textcoords='offset points', ha='center', va='bottom' if v > 0 else 'top', fontsize=7)\n",
    "            j += 1\n",
    "\n",
    "        sns.scatterplot(df_pc_human, x='length', y='human', marker='x')\n",
    "        ax_1.set_ylim((0., 1.1))\n",
    "        #ax_1.invert_yaxis()\n",
    "\n",
    "        ax_1.set_ylabel('')\n",
    "        ax_1.set_xlabel('')\n",
    "        #ax_1.set_ylim((_lens[-1], _lens[0]))\n",
    "\n",
    "\n",
    "        #\n",
    "        # presented non-self kmers\n",
    "        #\n",
    "        \n",
    "        ax_2 = fig.add_subplot(gs[i, 2])  #, sharey=axes[1, 0])\n",
    "        axes[i, 2] = ax_2          \n",
    "        sns.boxplot(_df, y='source_id', x='pnip', hue='source_id', palette=palette_source_id, ax=ax_2)\n",
    "        \n",
    "        ax_2.text(x=_df.pnip.max()+0.01, y=.25, s=f'avg={_df.pnip.mean():.1%}', verticalalignment='bottom', horizontalalignment='left') # add mean value\n",
    "        ax_2.get_legend().remove()\n",
    "        ax_2.set_xlabel('')\n",
    "        ax_2.set_ylabel('')\n",
    "        ax_2.set_yticklabels([])\n",
    "        ax_2.set_xlim((0., x_lim_pnip))\n",
    "        \n",
    "        ax_1.xaxis.set_ticks_position('top')\n",
    "        ax_1.xaxis.set_label_position('top')\n",
    "        ax_2.xaxis.set_ticks_position('top')\n",
    "        ax_2.xaxis.set_label_position('top')\n",
    "        if i != 0 or not show_x_labels:\n",
    "            ax_1.set_xticklabels([])\n",
    "            ax_2.set_xticklabels([])\n",
    "        else:\n",
    "            ax_1.set_xlabel(\"from genome \\n [fraction of kmers]\")\n",
    "            ax_2.set_xlabel('presented 8-10mers \\n not in proteome \\n [fraction of 8-10mers]')\n",
    "            \n",
    "            ax_1.set_xticks(_lens)\n",
    "            ax_1.set_xticklabels(_lens)\n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63c2da35-a47f-4f94-96d2-28904c2b7fe9",
   "metadata": {},
   "source": [
    "### Plot fig B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e348caa-865d-410f-8dde-bf6111cd554d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_fig_B(df, palette_source_id, rename_source_ids, fig_width=None, ylabel=True, min_tm_score=None):\n",
    "    infos = ['rosetta p.a.', 'aggrescan3d max', 'delta isoelectric point']\n",
    "\n",
    "    if min_tm_score is not None:\n",
    "        df = df.query(f\"tm_score >= {min_tm_score}\")\n",
    "\n",
    "    fig_width = A4_width if fig_width is None else fig_width\n",
    "    fig = plt.figure(figsize=(fig_width, A4_height/2))\n",
    "    gs = gridspec.GridSpec(len(infos), # rows\n",
    "                           1, # cols\n",
    "                           width_ratios=[1],\n",
    "                           height_ratios=[1]*len(infos),\n",
    "                           hspace=0.1,\n",
    "                           wspace=0.1,\n",
    "                          )\n",
    "\n",
    "    for j, info in enumerate(infos):\n",
    "        ax = fig.add_subplot(gs[j, 0])\n",
    "        \n",
    "        sns.boxplot(\n",
    "            data=df,\n",
    "            x='source_id', \n",
    "            y=info, \n",
    "            palette=palette_source_id,\n",
    "            ax=ax\n",
    "        )\n",
    "\n",
    "        if j < len(infos) - 1:\n",
    "            ax.set_xticklabels([])\n",
    "        else:\n",
    "            labels = []\n",
    "            for h in ax.get_xticklabels():\n",
    "                source_id = h.get_text()\n",
    "                n_designs = len(df.query(f\"source_id == '{source_id}'\"))\n",
    "                labels.append(f\"{rename_source_ids.get(source_id, source_id)}\\n N={n_designs}\")\n",
    "            ax.set_xticklabels(labels, rotation=50)\n",
    "\n",
    "        if not ylabel:\n",
    "            ax.set_ylabel(\"\")\n",
    "\n",
    "        if info == 'rosetta p.a.':\n",
    "            plt.axhline(y=-1.0, color='red', linestyle='--')\n",
    "            \n",
    "        ax.set_xlabel('')\n",
    "\n",
    "        # plt.axvline(x=len(benchmark_source_ids) - 0.5, color='green')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "859e9764-5f5e-45f2-8c8e-75d8da7b3a4e",
   "metadata": {},
   "source": [
    "### Plot fig C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3c0b315-ceda-4868-827f-afb06d5791eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_min_diff(df, closest_pkmer=None, save=True):\n",
    "    closest_pkmer_file_path = os.path.join(G.ENV.ARTEFACTS, \"eval\", \"closest_pkmer.pickle\")\n",
    "    if closest_pkmer is None:\n",
    "        closest_pkmer = {}\n",
    "        if os.path.exists(closest_pkmer_file_path):\n",
    "            with open(closest_pkmer_file_path, \"rb\") as f:\n",
    "                closest_pkmer = pickle.load(f)\n",
    "\n",
    "    \n",
    "    df['avg_min_diff'] = None\n",
    "    df['max_min_diff'] = None\n",
    "    df['min_diff'] = None\n",
    "    \n",
    "    for i, row in df.iterrows():\n",
    "        kmers_not_in_proteome = [kmer for kmer in row.kmers_not_in_proteome if len(kmer) in MHC_1_PEPTIDE_LENGTHS]\n",
    "    \n",
    "        min_diff = []\n",
    "        for kmer in kmers_not_in_proteome:\n",
    "            l = len(kmer)\n",
    "            if kmer not in closest_pkmer:       \n",
    "                max_score = -1000\n",
    "                max_pkmer = None\n",
    "                for pkmer in proteome_kmers_per_length[l]:\n",
    "                    score = aligner.score(kmer, pkmer)\n",
    "                    if score > max_score:\n",
    "                        max_pkmer, max_score = pkmer, score\n",
    "    \n",
    "                closest_pkmer[kmer] = (max_pkmer, max_score)\n",
    "            else:\n",
    "                max_pkmer, max_score = closest_pkmer[kmer]\n",
    "                \n",
    "            min_diff.append(aligner.score(kmer, kmer) - max_score)\n",
    "\n",
    "        df.at[i, 'min_diff'] = min_diff\n",
    "        chain = row.seq.split('/')[0]\n",
    "        # print(f\"{row.protein_id} {row.source_id} {len(chain)*3 - (9 + 8 +7)} {len(min_diff)}\")\n",
    "        if len(kmers_not_in_proteome) > 0:\n",
    "            df.at[i, 'avg_min_diff'] = np.mean(min_diff)\n",
    "            df.at[i, 'max_min_diff'] = np.max(min_diff)\n",
    "\n",
    "        if save:\n",
    "            with open(closest_pkmer_file_path, \"wb\") as f:\n",
    "                pickle.dump(closest_pkmer, f)\n",
    "\n",
    "    return closest_pkmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be097d28-b0e1-4459-b787-d854784f8769",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_dissimilarity_protein(df, protein_id, source_ids, area, ylabel=True, rename_source_ids=None, palette=None, \n",
    "                               source_label_fontsize=7, min_tm_score=None, \n",
    "                               dissimilarity_column='min_diff', dissimilarity_label=\"BLOSUM62\\ndissimilarity\", dissimilarity_scale='linear'):\n",
    "    fig = plt.gcf()\n",
    "    #with sns.axes_style(\"whitegrid\"):\n",
    "    ax = fig.add_subplot(area)\n",
    "\n",
    "    source_names, min_diffs = {}, {}\n",
    "    _df = {'source_name': [], dissimilarity_column: []}\n",
    "    for source_id in source_ids:\n",
    "        source_names[source_id] = rename_source_ids[source_id] if (rename_source_ids is not None and source_id in rename_source_ids) else source_id\n",
    "        \n",
    "        rows = df.query(f\"protein_id == '{protein_id}' and source_id == '{source_id}'\")\n",
    "        assert len(rows) == 1\n",
    "        row = rows.iloc[0]\n",
    "        if min_tm_score is not None and row.tm_score < min_tm_score:\n",
    "            continue\n",
    "        \n",
    "        _df['source_name'] += [source_id] * len(row.min_diff)\n",
    "        _df[dissimilarity_column] += row[dissimilarity_column]  # row[similarity_column] is a list\n",
    "        min_diffs[source_id] = row[dissimilarity_column]\n",
    "\n",
    "    _df = pd.DataFrame(_df)\n",
    "    sns.boxplot(data=_df, x='source_name', y=dissimilarity_column, order=source_ids, palette=palette, ax=ax)\n",
    "    labels = [f\"{source_names[h]}\\nn={len(min_diffs[h]) if h in min_diffs else 'NA'}\" for h in source_ids]\n",
    "    ax.set_xticklabels(labels, rotation=50, fontsize=source_label_fontsize)\n",
    "    ax.set_ylabel(dissimilarity_label if ylabel else '')\n",
    "    ax.set_yscale(dissimilarity_scale)\n",
    "    ax.set_xlabel('')    \n",
    "    plt.title(protein_id)\n",
    "\n",
    "def plot_dissimilarity(df, protein_ids, source_ids, rename_source_ids=None, n_cols=3, fig_width=None, fig_height=None, \n",
    "                       palette=None, wspace=0.25, hspace=0.5, source_label_fontsize=7, min_tm_score=None, \n",
    "                       dissimilarity_column='min_diff', dissimilarity_label=\"BLOSUM62\\ndissimilarity\", dissimilarity_scale='linear'\n",
    "                      ):\n",
    "    n_rows = int(np.ceil(len(protein_ids)/n_cols))\n",
    "\n",
    "    fig_width = A4_width if fig_width is None else fig_width\n",
    "    fig_height = min(A4_height*0.25*n_rows, A4_height) if fig_height is None else fig_height\n",
    "    fig = plt.figure(figsize=(fig_width, fig_height))\n",
    "    gs = mpl.gridspec.GridSpec(\n",
    "            n_rows,\n",
    "            n_cols,\n",
    "            height_ratios=[1] * n_rows,\n",
    "            width_ratios=[1] * n_cols,\n",
    "            wspace=wspace, hspace=hspace\n",
    "    )\n",
    "\n",
    "    for i, protein_id in enumerate(protein_ids):\n",
    "        i_col = i % n_cols\n",
    "        i_row = i // n_cols\n",
    "    \n",
    "        plot_dissimilarity_protein(df, protein_id, source_ids, \n",
    "                                   gs[i_row, i_col], ylabel=(i_col == 0), rename_source_ids=rename_source_ids, \n",
    "                                   palette=palette, source_label_fontsize=source_label_fontsize, \n",
    "                                   min_tm_score=min_tm_score, \n",
    "                                   dissimilarity_column=dissimilarity_column, \n",
    "                                   dissimilarity_label=dissimilarity_label,\n",
    "                                   dissimilarity_scale=dissimilarity_scale\n",
    "        )\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00e6f1e1-b52c-4ec2-8ce1-fc2ff7357d6a",
   "metadata": {},
   "source": [
    "## Destress"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2629bea-e1a7-4068-80d8-be809f689f12",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_destress(df):\n",
    "    seq_hashes_exp = []\n",
    "    seq_hashes_AF = []\n",
    "    seq_hashes_CAPE_MPNN = []\n",
    "    \n",
    "    for idx, row in df.iterrows():\n",
    "        if row.seq_hash is not None and isinstance(row.seq_hash, str):\n",
    "            if row.source_id in ['template']:\n",
    "                seq_hashes_exp.append(row.seq_hash)\n",
    "            elif row.tm_score is not None:\n",
    "                seq_hashes_AF.append(row.seq_hash)\n",
    "    \n",
    "    if DESTRESS_PROG_DIR_PATH is None:\n",
    "        print(\"DESTRESS_PROG_DIR_PATH not set\")\n",
    "        str_to_file('\\n'.join(seq_hashes_exp), join(G.ENV.ARTEFACTS, 'eval', 'de-stress', 'for_destress_exp.txt'))\n",
    "        str_to_file('\\n'.join(seq_hashes_AF), join(G.ENV.ARTEFACTS, 'eval', 'de-stress', 'for_destress_AF.txt'))\n",
    "    else:\n",
    "        loch.run_destress(\n",
    "            seq_hashes_exp, \n",
    "            DESTRESS_PROG_DIR_PATH, \n",
    "            predictor_structure_name='exp'\n",
    "        )\n",
    "        loch.run_destress(\n",
    "            seq_hashes_AF, \n",
    "            DESTRESS_PROG_DIR_PATH, \n",
    "            predictor_structure_name='AF'\n",
    "        )\n",
    "\n",
    "    return seq_hashes_exp, seq_hashes_AF"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a6c587e-328a-4b99-b800-5afd90bb5267",
   "metadata": {},
   "source": [
    "# Load systems"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45f5c60a-18a3-4b73-98f0-e54431ad5e26",
   "metadata": {},
   "source": [
    "## Loch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7325d5d5-1eed-43e8-b8ae-b5da9a6bbf82",
   "metadata": {},
   "outputs": [],
   "source": [
    "loch = Loch(loch_path=LOCH_PATH)\n",
    "kit.loch.path.set_loch_path(LOCH_PATH)\n",
    "Protein.loch = loch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5f14c7f-8fdc-4a66-a83b-68fdad4d5399",
   "metadata": {},
   "source": [
    "## Immuno-Predictors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4dda424-19b3-4572-a85f-a55629db9dd7",
   "metadata": {},
   "source": [
    "### NetMHCpan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dd6efa2-fe7e-4304-a9c2-bbf2ea8394e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor_MHC_I_netmhcpan_dd = DD.from_yaml(\n",
    "    os.path.join(\n",
    "        G.PROJECT_ENV.CONFIG, \n",
    "        'immuno', \n",
    "        'mhc_1_predictor', \n",
    "        f'netmhcpan.yaml'\n",
    "    )\n",
    ")\n",
    "\n",
    "predictor_MHC_I_netmhcpan_args = {\n",
    "    'data_dir_path': NETMHCPAN_DIR_PATH,\n",
    "    'limit': predictor_MHC_I_netmhcpan_dd.PREDICTOR_MHC_I.LIMIT,\n",
    "}\n",
    "if \"LIMIT_CALIBRATION\" in predictor_MHC_I_netmhcpan_dd.PREDICTOR_MHC_I:\n",
    "    predictor_MHC_I_netmhcpan_args.update({'limit_calibration': predictor_MHC_I_netmhcpan_dd.PREDICTOR_MHC_I.LIMIT_CALIBRATION})\n",
    "predictor_MHC_I_netmhcpan = Mhc1Predictor.get_predictor(predictor_MHC_I_netmhcpan_dd.PREDICTOR_MHC_I.NAME)(**predictor_MHC_I_netmhcpan_args)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2c0ade7-1c9e-4e3c-913c-b4cb000448a0",
   "metadata": {},
   "source": [
    "### PWM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d68c9298-44c3-40fd-8c62-3f717c751a9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor_MHC_I_pwm_dd = DD.from_yaml(\n",
    "    os.path.join(\n",
    "        G.PROJECT_ENV.CONFIG, \n",
    "        'immuno', \n",
    "        'mhc_1_predictor', \n",
    "        f'pwm_dynamic.yaml'\n",
    "    )\n",
    ")\n",
    "\n",
    "predictor_MHC_I_dd_args = {\n",
    "    'data_dir_path': predictor_MHC_I_pwm_dd.PREDICTOR_MHC_I.FOLDER, \n",
    "    'limit': predictor_MHC_I_pwm_dd.PREDICTOR_MHC_I.LIMIT,\n",
    "}\n",
    "if \"LIMIT_CALIBRATION\" in predictor_MHC_I_pwm_dd.PREDICTOR_MHC_I:\n",
    "    predictor_MHC_I_dd_args['limit_calibration'] = predictor_MHC_I_pwm_dd.PREDICTOR_MHC_I.LIMIT_CALIBRATION\n",
    "predictor_MHC_I_pwm = Mhc1Predictor.get_predictor(predictor_MHC_I_pwm_dd.PREDICTOR_MHC_I.NAME)(**predictor_MHC_I_dd_args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16396bd0-cb6e-4d8d-9a97-8df7edba9336",
   "metadata": {},
   "outputs": [],
   "source": [
    "immuno_predictor_setups = {\n",
    "    'netmhcpan': {'mhc_1': predictor_MHC_I_netmhcpan}, \n",
    "    'pwm_dynamic': {'mhc_1': predictor_MHC_I_pwm}\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97f8a1a0-c66d-49dc-9cd2-d559935e96ff",
   "metadata": {},
   "source": [
    "## Proteome"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6db554bc-170c-4890-936a-dcbca688f18e",
   "metadata": {},
   "source": [
    "### Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "629a0033-55c2-4723-a91e-ecb11714b7c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "proteome_pickle_file_path = os.path.join(G.ENV.INPUT, \"proteomes\", f\"{PROTEOME_FILE_NAME}.pickle\")\n",
    "if not os.path.exists(proteome_pickle_file_path):\n",
    "    print(\"regenerate tree\")\n",
    "    proteome_hash, proteome_tree = load_proteome_tree(PROTEOME_FILE_NAME, alphabet=ALPHABET)\n",
    "    with open(proteome_pickle_file_path, \"wb\") as f:\n",
    "        pickle.dump(proteome_tree, f)\n",
    "else:\n",
    "    print(\"load from disk\")\n",
    "    with open(proteome_pickle_file_path, \"rb\") as f:\n",
    "        proteome_tree = pickle.load(f)\n",
    "    PrefixTree.set_alphabet(ALPHABET)\n",
    "\n",
    "print(f\"Nr of nodes: {proteome_tree.cnt_nodes}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3e7d3cb-8429-42d9-9fe4-5b06571aec0c",
   "metadata": {},
   "source": [
    "### Aligner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34177d37-c7ad-464c-b8db-927fa6504064",
   "metadata": {},
   "outputs": [],
   "source": [
    "aligner = Align.PairwiseAligner()\n",
    "aligner.substitution_matrix = substitution_matrices.load('BLOSUM62')\n",
    "aligner.mode = 'global'\n",
    "aligner.open_gap_score = -1e6\n",
    "aligner.extend_gap_score = -1e6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "014dd640-fc4b-4cea-97a3-d3efe0d472b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "proteome_file_path = os.path.join(G.ENV.INPUT, \"proteomes\", PROTEOME_FILE_NAME)\n",
    "proteome = read_fasta(proteome_file_path, stop_token=False, evaluate=False, return_df=True)\n",
    "proteome_kmers = get_kmers(list(proteome.index), lengths=MHC_1_PEPTIDE_LENGTHS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a81237e-8f20-4bc0-af25-e2730dd508f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(proteome_kmers))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0104b75-1def-42ae-ac8d-4f2b76e97b1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "proteome_kmers_per_length = {l: set() for l in MHC_1_PEPTIDE_LENGTHS}\n",
    "\n",
    "for kmer in proteome_kmers:\n",
    "    proteome_kmers_per_length[len(kmer)].add(kmer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35f5a156-4261-409c-b3b7-1063d5a367e0",
   "metadata": {},
   "source": [
    "## Percent of random kmers in the human genome"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "299f9fd8-2747-47a2-bd78-f0811aee2603",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pc_human_file_path = join(G.ENV.ARTEFACTS, 'eval', 'df_pc_human.csv')\n",
    "\n",
    "if os.path.exists(df_pc_human_file_path):\n",
    "    df_pc_human = pd.read_csv(df_pc_human_file_path).set_index('length')\n",
    "else:\n",
    "    proteome_kmers = {l: set() for l in range(5, 11)}\n",
    "    for seq, row in tqdm(proteome.iterrows()):\n",
    "        for l in proteome_kmers.keys():\n",
    "            proteome_kmers[l].update(get_kmers(seq, l))\n",
    "\n",
    "\n",
    "    _lens, _pc = [], []\n",
    "    for l in proteome_kmers.keys():\n",
    "        print(f\"{l}  {len(proteome_kmers[l])/20**l:.3f}\")\n",
    "        _lens.append(l)\n",
    "        _pc.append(len(proteome_kmers[l])/20**l)\n",
    "    \n",
    "    df_pc_human = pd.DataFrame({'length': _lens, 'human': _pc}).set_index('length')    \n",
    "    df_pc_human.to_csv(df_pc_human_file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efd7ef21-5db5-4800-95e6-3d8fea90301d",
   "metadata": {},
   "source": [
    "## Load ProteinMPNN checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17b4136f-fea4-40cc-8752-e61409fc3ba8",
   "metadata": {},
   "outputs": [],
   "source": [
    "protein_mpnn = CapeMPNN.from_file(BASE_MODEL_NAME).eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5f9405d-ad2e-4fe1-9517-530e28a00d7c",
   "metadata": {},
   "source": [
    "## Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69e6b45c-0008-43d8-8499-d1f97587086b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_source_id(checked_kmer_length, proteome_file_name, min_self_kmer_length, tune_mhc_1_genotype, tune_mhc_1_predictor, non_self_prob_factor, width, branching_factor, depth, prune_min_acc_log_prob):\n",
    "    _predictor_setup_hash, _immuno_setup = None, None\n",
    "    if tune_mhc_1_genotype is not None:\n",
    "        _predictor_setup_hash = tune_mhc_1_predictor.get_predictor_hash()\n",
    "        _immuno_setup = {'mhc_1': tune_mhc_1_genotype}\n",
    "        \n",
    "    return get_beam_search_hash(\n",
    "        None, \n",
    "        checked_kmer_length, \n",
    "        proteome_file_name, \n",
    "        min_self_kmer_length, \n",
    "        0, \n",
    "        _immuno_setup, \n",
    "        _predictor_setup_hash, \n",
    "        20, \n",
    "        non_self_prob_factor, \n",
    "        width,\n",
    "        branching_factor,\n",
    "        depth,\n",
    "        prune_min_acc_log_prob\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4cc461f-04c6-4d74-bff7-75364ce18d52",
   "metadata": {},
   "outputs": [],
   "source": [
    "palette_source_id = ['template', 'standard', 'CAPE-MPNN'] # template, standard, CAPE-MPNN\n",
    "tmp = [3]\n",
    "\n",
    "rename_source_ids_X = {}\n",
    "rename_source_ids_A = {}\n",
    "rename_source_ids_B = {}\n",
    "rename_source_ids_C = {}\n",
    "\n",
    "for _min_self_kmer_length in PLOT_MIN_SELF_KMER_LENGTH:\n",
    "    new_source_ids = []\n",
    "    for _non_self_prob_factor in PLOT_NON_SELF_PROB_FACTORS:\n",
    "        source_id = get_source_id(\n",
    "            checked_kmer_length=10, \n",
    "            proteome_file_name=PROTEOME_FILE_NAME, \n",
    "            min_self_kmer_length=_min_self_kmer_length, \n",
    "            tune_mhc_1_genotype=person_mhc_1_genotype, \n",
    "            tune_mhc_1_predictor=immuno_predictor_setups[MHC_1_PREDICTOR_DECODING]['mhc_1'], \n",
    "            non_self_prob_factor=_non_self_prob_factor, \n",
    "            width=10, \n",
    "            branching_factor=1, \n",
    "            depth=_min_self_kmer_length*2, \n",
    "            prune_min_acc_log_prob=-2000.\n",
    "        )\n",
    "        rename_source_ids_X[source_id] = f\"CB {_min_self_kmer_length}mers ({_non_self_prob_factor})\"\n",
    "        rename_source_ids_A[source_id] = f\"CAPE-Beam ({_non_self_prob_factor})\"\n",
    "        rename_source_ids_B[source_id] = f\"{_min_self_kmer_length}mers ({_non_self_prob_factor})\"\n",
    "        rename_source_ids_C[source_id] = f\"CAPE-Beam\\n{_min_self_kmer_length}mers ({_non_self_prob_factor})\"\n",
    "        \n",
    "        new_source_ids.append(source_id)\n",
    "        \n",
    "    palette_source_id += new_source_ids\n",
    "    tmp.append(len(new_source_ids))\n",
    "\n",
    "tmp = glasbey.create_block_palette(tmp)\n",
    "palette_source_id = {k: tmp[i] for i, k in enumerate(palette_source_id)}\n",
    "markers_source_id = {k: 'o' for i, k in enumerate(palette_source_id)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05451853-8dcc-47d9-8e49-54e8db55d329",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.palplot(tmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60b6b4c5-8e46-4d47-acee-2b7c319bb279",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_plot = {}\n",
    "selected_source_ids = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ad88939-5704-43f3-8f8c-0292ba709c34",
   "metadata": {},
   "source": [
    "# Identify alternative genotypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4be75628-8160-4c5d-b600-68016030c644",
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(alternative_mhc_1_genotypes) == 0:\n",
    "    #\n",
    "    # get the peptide ranks of the alleles to compare to\n",
    "    #\n",
    "    allele_ranks = {}\n",
    "    peptides = None\n",
    "    for mhc_1_allele in person_mhc_1_genotype_list:\n",
    "        result = re.findall(r\"^HLA-(A|B|C)\\*(\\d+):(\\d+)$\", mhc_1_allele)[0]\n",
    "        file_name = r\"HLA-{}_{}:{}.csv\".format(*result)\n",
    "        df = pd.read_csv(os.path.join(PEPTIDE_RANKS_DIR_PATH, file_name)).set_index('peptide')\n",
    "        if peptides is None:\n",
    "            peptides = list(df.index)\n",
    "        else:\n",
    "            assert len(set(peptides) ^ set(df.index)) == 0\n",
    "    \n",
    "        gene = result[0]\n",
    "        allele_ranks[mhc_1_allele] = df\n",
    "\n",
    "\n",
    "    #\n",
    "    # calcuate the 'distance' of all available alles to the already available alleles\n",
    "    #    \n",
    "    available_alleles = {}\n",
    "    for file_name in tqdm([d for d in os.listdir(PEPTIDE_RANKS_DIR_PATH) if d.endswith(\".csv\")]):\n",
    "        result = re.findall(r\"HLA-(A|B|C)_(\\d+):(\\d+).csv\", file_name)\n",
    "        if len(result) == 1:\n",
    "            result = result[0]\n",
    "            gene = result[0]\n",
    "            allele_name = f\"HLA-{gene}*{result[1]}:{result[2]}\"\n",
    "            if allele_name not in person_mhc_1_genotype_list:\n",
    "                df = pd.read_csv(os.path.join(PEPTIDE_RANKS_DIR_PATH, file_name)).set_index('peptide')\n",
    "                assert len(set(peptides) ^ set(df.index)) == 0\n",
    "                if all([type(x) == float for x in list(df[allele_name])]):\n",
    "                    dist = []\n",
    "                    for mhc_1_allele, df2 in allele_ranks.items():\n",
    "                        df3 = df.join(df2)\n",
    "                        dist.append(np.sum((df3[mhc_1_allele] <= DISTANCE_RANK_THRESHOLD) != (df3[allele_name] <= DISTANCE_RANK_THRESHOLD))/df3.shape[0])\n",
    "    \n",
    "                    available_alleles[gene] = available_alleles.get(gene, list())\n",
    "                    min_distance = min(dist)\n",
    "                    \n",
    "                    available_alleles[gene].append((allele_name, dist, min_distance))\n",
    "\n",
    "    #\n",
    "    # Take the most distant alleles, make sure they belong to different groups\n",
    "    #\n",
    "    alternative_mhc_1_genotypes = []\n",
    "    for gene in ['A', 'B', 'C']:\n",
    "        sorted_available_alleles = sorted(available_alleles[gene], key=lambda x: -x[2])\n",
    "        \n",
    "        print(gene)\n",
    "        found, group = 0, \"\"\n",
    "        for sorted_allele in sorted_available_alleles:\n",
    "            result = re.findall(r\"^HLA-(A|B|C)\\*(\\d+):(\\d+)$\", sorted_allele[0])[0]\n",
    "            _group = result[1]\n",
    "            if _group != group:\n",
    "                print(f\"  {sorted_allele}\")\n",
    "                found += 1\n",
    "                alternative_mhc_1_genotypes.append(sorted_allele[0])\n",
    "                if found >= 2:\n",
    "                    break\n",
    "                group = _group\n",
    "                \n",
    "    alternative_mhc_1_genotypes = '+'.join(alternative_mhc_1_genotypes)\n",
    "    print(alternative_mhc_1_genotypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d49c364d-32c6-4434-81df-22ea59e56917",
   "metadata": {},
   "outputs": [],
   "source": [
    "split_mhc_1_genotypes = {\n",
    "    Split.VAL: [person_mhc_1_genotype],\n",
    "    Split.TEST: [person_mhc_1_genotype] + alternative_mhc_1_genotypes,\n",
    "    Split.PREDICT: [person_mhc_1_genotype],\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7687de26-b9c6-4d0b-b874-dc6843aab111",
   "metadata": {},
   "source": [
    "# Analyse PWM predictor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04c0737f-f3f5-4c86-9c17-0e42a666c5ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "if ANALYSE_PWM_PREDICTOR == True:\n",
    "    peptide_intersect = None\n",
    "    pred = immuno_predictor_setups['pwm_dynamic']['mhc_1']\n",
    "    person_allele_ranks = {}\n",
    "    peptides = {s: None for s in [Split.TRAIN, Split.TEST]}\n",
    "    print(rf\"{'allele':15s} & {'kmer len':10s} & {'accuracy':10s} & {'precision':10s} & {'recall':10s} & {'accuracy':10s} & {'precision':10s} & {'recall':10s} \\\\\")\n",
    "    for mhc_1_genotype in all_mhc_1_genotypes:\n",
    "        for mhc_1_allele in mhc_1_genotype.split('+'):\n",
    "            for l in [8,9,10]:\n",
    "                pred.load_allele(mhc_1_allele, l)\n",
    "            \n",
    "            result = re.findall(r\"^HLA-(A|B|C)\\*(\\d+):(\\d+)$\", mhc_1_allele)[0]\n",
    "            file_name = r\"HLA-{}_{}:{}.csv\".format(*result)\n",
    "\n",
    "            dfs = {}\n",
    "            for split, ranks_dir_path in [(Split.TRAIN, PEPTIDE_RANKS_DIR_PATH), (Split.TEST, PWM_PREDICTOR_TEST_RANKS_DIR_PATH)]:\n",
    "                df = pd.read_csv(os.path.join(ranks_dir_path, file_name)).set_index('peptide')\n",
    "                df['PWM'] = df.apply(lambda r: pred.peptide_presented(r.name, mhc_1_allele), axis=1)\n",
    "                df['netMHCpan'] = df[mhc_1_allele] < pred.limit_calibration\n",
    "                df['length'] = df.apply(lambda row: len(row.name), axis=1)\n",
    "                df['TP'] = (df['PWM'] == True) & (df['netMHCpan'] == True)\n",
    "                df['FP'] = (df['PWM'] == True) & (df['netMHCpan'] == False)\n",
    "                df['FN'] = (df['PWM'] == False) & (df['netMHCpan'] == True)\n",
    "                df['TN'] = (df['PWM'] == False) & (df['netMHCpan'] == False)               \n",
    "                dfs[split] = df\n",
    "\n",
    "                if peptides[split] is not None:\n",
    "                    assert len(peptides[split] ^ set(df.index)) == 0\n",
    "                else:\n",
    "                    peptides[split] = set(df.index)\n",
    "            \n",
    "            print(r\"\\hline\")\n",
    "            _considered_k = [8, 9, 10] \n",
    "            for k in [None]+_considered_k:\n",
    "                _k = '+'.join([str(x) for x in _considered_k]) if k is None else str(k)\n",
    "                text = [rf\"{mhc_1_allele:15s} & {_k:10s}\"]\n",
    "                for split in [Split.TRAIN, Split.TEST]:\n",
    "                    _df = dfs[split]\n",
    "                    if k is not None:\n",
    "                        _df = _df.query(f\"length == {k}\")\n",
    "                        \n",
    "                    TP = _df['TP'].sum()\n",
    "                    FP = _df['FP'].sum()\n",
    "                    FN = _df['FN'].sum()\n",
    "                    TN = _df['TN'].sum()\n",
    "    \n",
    "                    text.append(rf\"{(TP + TN) / (TP + TN + FP + FN):10.3f} & {TP/(TP + FP):10.3f} & {TP/(TP + FN):10.3f}\")\n",
    "                text = \" & \".join(text) + r' \\\\'\n",
    "                print(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b969f4a-d44a-4874-9787-5375c2217f34",
   "metadata": {},
   "source": [
    "# Proteins"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2a41025-1e7a-4ea5-8fe9-1b0b64a84d45",
   "metadata": {},
   "source": [
    "## Identify specific proteins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8b5b5c0-8dce-48a7-a8bb-ef9fbed5e8eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "split_pdb_ids_file_path = os.path.join(G.ENV.ARTEFACTS, \"eval\", \"split_pdb_ids.pickle\")\n",
    "specific_proteins_file_path = os.path.join(G.ENV.ARTEFACTS, \"eval\", \"specific_proteins.pickle\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8cae87d-fec0-487c-a7da-3320e0768a9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "specific_proteins = {split: [] for split in [Split.VAL, Split.TEST, Split.PREDICT]}\n",
    "if os.path.exists(specific_proteins_file_path):\n",
    "    with open(specific_proteins_file_path, \"rb\") as f:\n",
    "        specific_proteins = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e06d517-7449-45f6-bfdb-607a7fd877a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "split_pdb_ids = {split: set() for split in [Split.TRAIN, Split.VAL, Split.TEST]}\n",
    "if IDENTIFY_SPECIFIC:\n",
    "    # read all the validation and test clusters\n",
    "    clusters_val = set([int(x) for x in file_to_str(os.path.join(GENERAL_DATA_DIR_PATH, 'valid_clusters.txt')).split('\\n') if x != ''])\n",
    "    clusters_test = set([int(x) for x in file_to_str(os.path.join(GENERAL_DATA_DIR_PATH, 'test_clusters.txt')).split('\\n') if x != ''])\n",
    "    df_data_list = pd.read_csv(os.path.join(GENERAL_DATA_DIR_PATH, 'list.csv'))\n",
    "    \n",
    "    assert df_data_list.shape[0] == len(set(df_data_list.CHAINID))\n",
    "    \n",
    "    # construct the sets of train, validation and test chain_ids\n",
    "    chains_split = {split: set() for split in [Split.TRAIN, Split.VAL, Split.TEST]}\n",
    "    for _, row in df_data_list.iterrows():\n",
    "        found = False\n",
    "        if row.CLUSTER in clusters_test:\n",
    "            chains_split[Split.TEST].add(row.CHAINID)\n",
    "            found = True\n",
    "        if row.CLUSTER in clusters_val:\n",
    "            chains_split[Split.VAL].add(row.CHAINID)\n",
    "            found = True\n",
    "        if not found:\n",
    "            chains_split[Split.TRAIN].add(row.CHAINID)\n",
    "    \n",
    "    assert np.sum([len(c) for c in chains_split.values()]) == df_data_list.shape[0] \n",
    "    \n",
    "    for split, chains in chains_split.items():\n",
    "        for chain in chains:\n",
    "            split_pdb_ids[split].add(chain.split('_')[0].upper())\n",
    "\n",
    "    candidate_specific_pdb_ids = {}\n",
    "    for split in [Split.VAL, Split.TEST]:\n",
    "        candidate_specific_pdb_ids[split] = filter_pdbs(\n",
    "            [x for x in split_pdb_ids[split]], \n",
    "            PDB_DIR_PATH, \n",
    "            max_unmodelled=CANDIDATE_MAX_UNMODELLED,\n",
    "            exclude_small_molecules=CANDIDATE_EXCLUDE_SMALL_MOLECULES,\n",
    "            exclude_complexes=True,\n",
    "            server=PDB_SERVER\n",
    "        )\n",
    "        print(f\"Number of {split} candidates: {len(candidate_specific_pdb_ids[split])}\")\n",
    "\n",
    "    with open(split_pdb_ids_file_path, \"wb\") as f:\n",
    "        pickle.dump(split_pdb_ids, f)\n",
    "\n",
    "if os.path.exists(split_pdb_ids_file_path):\n",
    "    with open(split_pdb_ids_file_path, \"rb\") as f:\n",
    "        split_pdb_ids = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1933426-a3c4-4533-80b7-6ccf0e45f7e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "if IDENTIFY_SPECIFIC:\n",
    "    # check overlaps are all in complexes\n",
    "    for split_1 in [Split.TRAIN, Split.VAL, Split.TEST]:\n",
    "        for split_2 in [Split.TRAIN, Split.VAL, Split.TEST]:\n",
    "            if split_1 != split_2:\n",
    "                overlap = set(split_pdb_ids[split_1]) & set(split_pdb_ids[split_2])\n",
    "                if len(overlap) > 0:\n",
    "                    print(f\"{split_1} {split_2} {overlap}\")\n",
    "                    for pdb_id in overlap:\n",
    "                        print(f\" {pdb_id}\")\n",
    "                        print(f\"  {split_1}: \", end='')\n",
    "                        c_1 = set()\n",
    "                        for pdb_id_1 in chains_split[split_1]:\n",
    "                            if pdb_id_1.upper().split('_')[0] == pdb_id:\n",
    "                                print(f\"{pdb_id_1} \", end='')\n",
    "                                c_1.add(pdb_id_1)\n",
    "                        print(\"\")\n",
    "    \n",
    "                        print(f\"  {split_2}: \", end='')\n",
    "                        for pdb_id_2 in chains_split[split_2]:\n",
    "                            if pdb_id_2.upper().split('_')[0] == pdb_id:\n",
    "                                print(f\"{pdb_id_2} \", end='')\n",
    "                                if pdb_id_2 in c_1:\n",
    "                                    raise Exception(\"overlap!\")\n",
    "                        print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8881c6f8-985a-4850-96eb-b5fdc6cb02c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "if IDENTIFY_SPECIFIC:\n",
    "    for split in [Split.VAL, Split.TEST]:\n",
    "        np.random.seed(SEED)\n",
    "        candidate_specific_pdb_ids[split] = np.random.permutation(sorted(candidate_specific_pdb_ids[split]))\n",
    "    \n",
    "    peer_groups = {split: {} for split in [Split.VAL, Split.TEST]}\n",
    "\n",
    "    split = Split.TEST\n",
    "    for pdb_id in sorted(candidate_specific_pdb_ids[split]):\n",
    "        peers = get_peers(pdb_id)\n",
    "    \n",
    "        if len(peers) > 0:              \n",
    "            found = None\n",
    "            for cid, cluster in peer_groups[split].items():\n",
    "                if pdb_id in cluster:\n",
    "                    found = cid\n",
    "            if found is None:\n",
    "                peer_groups[split][pdb_id] = [x[0] for x in peers.values()]\n",
    "\n",
    "\n",
    "    for pdb_id in list(peer_groups[Split.TEST]):\n",
    "        add_to_specific_proteins(specific_proteins[Split.TEST], pdb_id, peer_groups[Split.TEST], KEEP_CHAINS)\n",
    "    \n",
    "\n",
    "    for split in [Split.VAL, Split.TEST]:\n",
    "        i = 0\n",
    "        while len(specific_proteins[split]) < N_SPECIFIC[split]:\n",
    "            pdb_id = candidate_specific_pdb_ids[split][i]\n",
    "\n",
    "            add_to_specific_proteins(\n",
    "                specific_proteins[split], \n",
    "                pdb_id, \n",
    "                peer_groups[split],\n",
    "                KEEP_CHAINS\n",
    "            )\n",
    "\n",
    "            i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a96b0ecd-ff55-4d7a-a2fb-4d8b000cc53f",
   "metadata": {},
   "outputs": [],
   "source": [
    "LOAD_RESULTS = {s: True for s in Split}\n",
    "if SPECIFIC_MANUAL is not None:\n",
    "    for split in [Split.VAL, Split.TEST, Split.PREDICT]:        \n",
    "        if len(set(specific_proteins[split]) ^ set(SPECIFIC_MANUAL[split])) > 0:\n",
    "            LOAD_RESULTS[split] = False\n",
    "            print(split)\n",
    "\n",
    "        specific_proteins[split] = copy.deepcopy(SPECIFIC_MANUAL[split])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00c11903-fe27-4538-a20d-47b9856b1103",
   "metadata": {},
   "source": [
    "## Download protein info and check overlaps of Train/Val/Test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efa638f9-4c2b-4cda-8235-344373e14257",
   "metadata": {},
   "outputs": [],
   "source": [
    "HUMAN_PROTEINS = []  # ['1XGD']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b91b111-f521-4e21-a981-5f4388e23887",
   "metadata": {},
   "outputs": [],
   "source": [
    "protein_infos = {}\n",
    "proteins = {}\n",
    "\n",
    "for split in [Split.VAL, Split.TEST, Split.PREDICT]:\n",
    "    for pdb_id in specific_proteins[split]:\n",
    "        found = []\n",
    "        for _split in [Split.TRAIN, Split.VAL, Split.TEST]:\n",
    "            if pdb_id in split_pdb_ids[_split]:\n",
    "                found.append(_split)\n",
    "\n",
    "        pdb_file_path = os.path.join(PDB_DIR_PATH, f\"{pdb_id}.pdb\")\n",
    "        download_structure(pdb_id, PDB_DIR_PATH, overwrite=False, file_format=\"pdb\", source='pdb', server=PDB_SERVER)\n",
    "        protein_name, protein_organism = get_protein_name_organism(pdb_file_path)\n",
    "\n",
    "        protein = Protein.from_pdb(os.path.join(PDB_DIR_PATH, f\"{pdb_id}.pdb\"), keep_chains=KEEP_CHAINS.get(pdb_id, None))\n",
    "        protein.to_loch(predictor_structure_name='exp')\n",
    "        protein_infos[pdb_id] = (None, protein.get_protein_type(), 'pdb')\n",
    "        proteins[pdb_id] = protein\n",
    "        \n",
    "        print(f\"{pdb_id} {len(protein.get_seq())} {protein.get_protein_type()}: {found} {protein_organism} - {protein_name}\")\n",
    "        if protein_organism == 'homo sapiens':\n",
    "            HUMAN_PROTEINS.append(pdb_id)\n",
    "        \n",
    "        if split != Split.PREDICT:\n",
    "            assert all(f == split for f in found)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9ff2daa-ed01-428b-8883-c87101a968d2",
   "metadata": {},
   "source": [
    "# Code for splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0ca6e57-ff9d-4163-a67e-b357e4f5fc3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def restrict_df_plot(fig_config, df_plot):\n",
    "    query, suffix = [], []\n",
    "    for k, v in fig_config.items():\n",
    "        q, s = [], []\n",
    "        for _v in v:\n",
    "            if type(_v) == str:\n",
    "                q.append(f\"{k} == '{_v}'\")\n",
    "            elif _v is None:\n",
    "                q.append(f\"{k}.isnull()\")\n",
    "            else:\n",
    "                q.append(f\"{k} == {_v}\")\n",
    "            \n",
    "            if k == 'eval_mhc_1_genotype':\n",
    "                s.append(get_mhc_1_setup_hash(_v))\n",
    "            else:\n",
    "                s.append(str(_v))\n",
    "\n",
    "        query.append('(' + ' or '.join(q) + ')')\n",
    "        suffix.append('_'.join(s))\n",
    "\n",
    "    query = \" and \".join(query)\n",
    "    suffix = '__'.join(suffix)\n",
    "\n",
    "    return df_plot.query(query), query, suffix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cf65d16-533a-4b5a-bb42-9b8d9db69d40",
   "metadata": {},
   "outputs": [],
   "source": [
    "shared_code = []\n",
    "\n",
    "# 0\n",
    "shared_code.append(\"\"\"\n",
    "df_decodings_file_path = os.path.join(G.ENV.ARTEFACTS, \"eval\", f\"df_decodings_{split}.pickle\")\n",
    "if LOAD_RESULTS[split] and os.path.exists(df_decodings_file_path):\n",
    "    with open(df_decodings_file_path, \"rb\") as f:\n",
    "        df_decodings = pickle.load(f)\n",
    "else:\n",
    "    df_decodings = get_df_decodings(benchmark_sources, specific_proteins[split], generate_min_proteome_kmer_lens, generate_non_self_prob_factors, split_mhc_1_genotypes[split])\n",
    "\"\"\")\n",
    "\n",
    "# 1\n",
    "shared_code.append(\"\"\"design_sequences(df_decodings, loch)\"\"\")\n",
    "\n",
    "# 2\n",
    "shared_code.append(\"\"\"to_colabfold(df_decodings, loch, ignore_seq_hashes=AF_ERRORS_SEQ_HASHES)\"\"\")\n",
    "\n",
    "# 3\n",
    "shared_code.append(\"\"\"\n",
    "from_colabfold(df_decodings, loch)\n",
    "# from_colabfold(list(df_decodings.query('source_id != \"template\"').seq_hash), loch)\n",
    "# template_pdbs_to_loch(df_decodings, loch)\n",
    "\"\"\")\n",
    "\n",
    "# 4\n",
    "shared_code.append(\"\"\"\n",
    "add_cape_mpnn_designs(df_decodings, CAPE_MPNN_CKPT_ID, loch) \n",
    "\"\"\")\n",
    "\n",
    "# 5\n",
    "shared_code.append(\"\"\"\n",
    "add_tm_data(df_decodings, loch, overwrite=OVERWRITE)\n",
    "\"\"\")\n",
    "\n",
    "# 6\n",
    "shared_code.append(\"\"\"analyse_kmer(df_decodings, overwrite=OVERWRITE)\"\"\")\n",
    "\n",
    "# 7\n",
    "shared_code.append(\"\"\"\n",
    "check_deimmunized(df_decodings, show=False)\n",
    "\n",
    "for _, row in df_decodings.iterrows():\n",
    "    if row.seq is None or len(row.seq) == 0:\n",
    "        print(f\"Seq is missing: {row.protein_id} {rename_source_ids_X[row.source_id]}\")\n",
    "    elif row.tm_data is None:\n",
    "        print(f\"TM data is missing: {row.protein_id} {rename_source_ids_X[row.source_id]}\")\n",
    "\"\"\")\n",
    "\n",
    "# 8\n",
    "shared_code.append(\"\"\"\n",
    "with open(df_decodings_file_path, \"wb\") as f:\n",
    "    pickle.dump(df_decodings, f)  \n",
    "\"\"\")\n",
    "\n",
    "# 9\n",
    "shared_code.append(\"\"\"df_plot[split] = get_df_plot(df_decodings)\"\"\")\n",
    "\n",
    "# 10\n",
    "shared_code.append(\"\"\"seq_hashes_exp, seq_hashes_AF = run_destress(df_plot[split])\"\"\")\n",
    "\n",
    "# 11\n",
    "shared_code.append(\"\"\"\n",
    "for seq_hash in seq_hashes_exp:\n",
    "    Protein.from_loch(seq_hash, predictor_structure_name='exp')\n",
    "    Protein.proteins[seq_hash].load_destress(predictor_structure_name='exp')\n",
    "\n",
    "for seq_hash in seq_hashes_AF:\n",
    "    Protein.from_loch(seq_hash, predictor_structure_name='AF')\n",
    "    Protein.proteins[seq_hash].load_destress(predictor_structure_name='AF')\n",
    "\n",
    "for idx, row in df_plot[split].iterrows():\n",
    "    if isinstance(row.seq_hash, str):\n",
    "        Protein.proteins[row.seq_hash].ref_seq_hash = df_plot[split].query(f\"protein_id == '{row.protein_id}' and source_id == 'template'\").iloc[0].seq_hash\n",
    "\n",
    "df_plot[split]['rosetta p.a.'] = df_plot[split].apply(\n",
    "    lambda r: \n",
    "    Protein.proteins[r.seq_hash].get_info('rosetta_total', delta=False)/len(r.seq) \n",
    "    if r.seq_hash in Protein.proteins else\n",
    "    None\n",
    ", axis=1)\n",
    "\n",
    "df_plot[split]['aggrescan3d max'] = df_plot[split].apply(\n",
    "    lambda r: \n",
    "    Protein.proteins[r.seq_hash].get_info('aggrescan3d_max', delta=False)\n",
    "    if r.seq_hash in Protein.proteins else\n",
    "    None\n",
    ", axis=1)\n",
    "\n",
    "df_plot[split]['delta isoelectric point'] = df_plot[split].apply(\n",
    "    lambda r: \n",
    "    Protein.proteins[r.seq_hash].get_info('isoelectric_point', delta=True)\n",
    "    if r.seq_hash in Protein.proteins else\n",
    "    None\n",
    ", axis=1)\n",
    "\n",
    "df_plot[split]['isoelectric point'] = df_plot[split].apply(\n",
    "    lambda r: \n",
    "    Protein.proteins[r.seq_hash].get_info('isoelectric_point', delta=False)\n",
    "    if r.seq_hash in Protein.proteins else\n",
    "    None\n",
    ", axis=1)\n",
    "\"\"\")\n",
    "\n",
    "\n",
    "# 12\n",
    "shared_code.append(\"\"\"\n",
    "for fig_X_config in fig_X_configs[split]:\n",
    "    _df, query, suffix = restrict_df_plot(fig_X_config, df_plot[split])\n",
    "\n",
    "    source_ids = get_successful_source_ids(_df, PLOT_MIN_TM_SCORE)\n",
    "    fig_X(_df, source_ids, rename_source_ids_X, palette_source_id, min_tm_score=PLOT_MIN_TM_SCORE, \n",
    "        homo_sapiens_proteins=HUMAN_PROTEINS, fig_height=0.7, hspace=.1, wspace=0.15, groupseps=[2,6,10])\n",
    "    \n",
    "    fig = plt.gcf()\n",
    "    fig.tight_layout()\n",
    "    if SAVE_FIGURES:\n",
    "        fig.savefig(join(G.ENV.ARTEFACTS, \"eval\", \"figures\", G.DOMAIN, \n",
    "            f\"figure_X_{split}__{suffix}.pdf\"), \n",
    "            bbox_inches='tight'\n",
    "        )\n",
    "\"\"\")\n",
    "\n",
    "# 13\n",
    "shared_code.append(\"\"\"\n",
    "for fig_A_config in fig_A_configs[split]:\n",
    "    _df, query, suffix = restrict_df_plot(fig_A_config, df_plot[split])\n",
    "\n",
    "    fig = plt.figure(figsize=(A4_width, A4_height))\n",
    "    gs = gridspec.GridSpec(4, 2, width_ratios=[1, 10], height_ratios=[2, 4, 4, 4], wspace=.6, hspace=.23)\n",
    "    \n",
    "    #ax = fig.add_subplot(gs[0, 0])\n",
    "    plot_fig_A(_df.query(f\"source_id in {benchmark_source_ids}\"), palette_source_id, area=gs[0, 1], x_lim_pnip=0.25, min_tm_score=PLOT_MIN_TM_SCORE)\n",
    "    for i, l in enumerate([5,6,7]):\n",
    "        ax = fig.add_subplot(gs[i+1, 0])\n",
    "        plot_text(f\"min human {l}-mers\", ax, rotation=90, y_pos=0.5)\n",
    "        plot_fig_A(\n",
    "            _df.query(f\"source_id in {selected_source_ids[split]['A']} and min_self_kmer_length == {l}\").\\\n",
    "                sort_values('non_self_prob_factor', ascending=False), \n",
    "            palette_source_id,\n",
    "            area=gs[i+1, 1],\n",
    "            rename_source_ids=rename_source_ids_A, x_lim_pnip=0.25, min_tm_score=PLOT_MIN_TM_SCORE, show_x_labels=False\n",
    "        )\n",
    "        \n",
    "    fig.tight_layout()\n",
    "    \n",
    "    if SAVE_FIGURES:\n",
    "        fig.savefig(join(G.ENV.ARTEFACTS, \"eval\", \"figures\", G.DOMAIN, \n",
    "            f\"figure_A_{split}__{suffix}.pdf\"), \n",
    "            bbox_inches='tight'\n",
    "        )\n",
    "\"\"\")\n",
    "\n",
    "# 14\n",
    "shared_code.append(\"\"\"\n",
    "for fig_B_config in fig_B_configs[split]:\n",
    "    _df, query, suffix = restrict_df_plot(fig_B_config, df_plot[split])\n",
    "\n",
    "    plot_fig_B(_df.query(f'source_id in {selected_source_ids[split][\"B\"]}'), palette_source_id, rename_source_ids_B, fig_width=fig_width_B, ylabel=ylabel_B, min_tm_score=PLOT_MIN_TM_SCORE)\n",
    "    \n",
    "    fig = plt.gcf()\n",
    "    fig.tight_layout()\n",
    "    if SAVE_FIGURES:\n",
    "        fig.savefig(join(G.ENV.ARTEFACTS, \"eval\", \"figures\", G.DOMAIN, \n",
    "            f\"figure_B_{split}__{suffix}.pdf\"), \n",
    "            bbox_inches='tight'\n",
    "        )\n",
    "\"\"\")\n",
    "\n",
    "# 15\n",
    "shared_code.append(\"\"\"\n",
    "dfs_fig_C = {}\n",
    "for fig_C_config in fig_C_configs[split]:\n",
    "    _df, query, suffix = restrict_df_plot(fig_C_config, df_plot[split])\n",
    "    df_fig_C = _df.query(f'source_id in {selected_source_ids[split][\"C\"]}').copy()\n",
    "    closest_pkmer = add_min_diff(df_fig_C, save=False)\n",
    "    dfs_fig_C[suffix] = df_fig_C\n",
    "\"\"\")\n",
    "\n",
    "# 16\n",
    "shared_code.append(\"\"\"\n",
    "protein_ids_separate = ['1XGD', '1B9K']\n",
    "n_cols=2\n",
    "hspace=0.75\n",
    "source_label_fontsize=7\n",
    "\"\"\")\n",
    "\n",
    "# 17\n",
    "shared_code.append(r\"\"\"\n",
    "for fig_C_config in fig_C_configs[split]:\n",
    "    _df, query, suffix = restrict_df_plot(fig_C_config, df_plot[split])\n",
    "\n",
    "    df_fig_C = dfs_fig_C[suffix]\n",
    "    \n",
    "    protein_ids = [x for x in  specific_proteins[split] if x not in protein_ids_separate] + protein_ids_separate\n",
    "\n",
    "    dissimilarity_column='min_diff'\n",
    "    plot_dissimilarity(df_fig_C, protein_ids, selected_source_ids[split]['C'], \n",
    "        rename_source_ids=rename_source_ids_X, \n",
    "        palette=palette_source_id, \n",
    "        n_cols=n_cols, \n",
    "        hspace=1., \n",
    "        min_tm_score=PLOT_MIN_TM_SCORE,\n",
    "        dissimilarity_column=dissimilarity_column,\n",
    "        dissimilarity_label='BLOSUM62\\ndissimilarity',\n",
    "        dissimilarity_scale='linear'\n",
    "    )\n",
    "    \n",
    "    fig = plt.gcf()\n",
    "    fig.tight_layout()\n",
    "    \n",
    "    if SAVE_FIGURES:\n",
    "        save_fig = join(G.ENV.ARTEFACTS, \"eval\", \"figures\", G.DOMAIN, f\"figure_C_{split}__{dissimilarity_column}__{suffix}.pdf\")\n",
    "        fig.savefig(save_fig, bbox_inches='tight')\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a8314b9-8de3-4eb0-983b-366903f11cf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "specific_code = {s: [None] * len(shared_code) for s in Split}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d87f797c-d928-4716-975e-f34020703a27",
   "metadata": {},
   "outputs": [],
   "source": [
    "specific_code[Split.PREDICT][13] = specific_code[Split.TEST][13] = \"\"\"\n",
    "for fig_A_config in fig_A_configs[split]:\n",
    "    _df, query, suffix = restrict_df_plot(fig_A_config, df_plot[split])\n",
    "\n",
    "    fig = plt.figure(figsize=(A4_width, A4_height/3))\n",
    "    gs = gridspec.GridSpec(2, 1, width_ratios=[10], height_ratios=[3, 2], wspace=.6, hspace=.23)\n",
    "\n",
    "    plot_fig_A(_df.query(f\"source_id in {benchmark_source_ids}\"), palette_source_id, area=gs[0, 0], x_lim_pnip=0.25, min_tm_score=PLOT_MIN_TM_SCORE)\n",
    "\n",
    "    plot_fig_A(\n",
    "        _df.query(f\"source_id in {selected_source_ids[split]['A']} and source_id not in {benchmark_source_ids}\").\\\n",
    "            sort_values('non_self_prob_factor', ascending=False), \n",
    "        palette_source_id, area=gs[1, 0],\n",
    "        rename_source_ids=rename_source_ids_C, x_lim_pnip=0.25, min_tm_score=PLOT_MIN_TM_SCORE, show_x_labels=False\n",
    "    )       \n",
    "    fig.tight_layout()\n",
    "    \n",
    "    if SAVE_FIGURES:\n",
    "        fig.savefig(join(G.ENV.ARTEFACTS, \"eval\", \"figures\", G.DOMAIN, \n",
    "            f\"figure_A_{split}__{suffix}.pdf\"), \n",
    "            bbox_inches='tight'\n",
    "        )\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "tmp = \"\"\"\n",
    "n_cols=4\n",
    "hspace=0.8\n",
    "source_label_fontsize=6   \n",
    "\"\"\"\n",
    "specific_code[Split.TEST][16] = \"\"\"protein_ids_separate = ['2BK8', '3WOY', '5OA9', '6TPT']\"\"\" + tmp\n",
    "specific_code[Split.PREDICT][16] =  \"\"\"protein_ids_separate = ['1UBQ', '1HHK']\"\"\" + tmp\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0230a678-1637-45c6-9255-2a9f53438bf0",
   "metadata": {},
   "source": [
    "# Val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87f07d5f-194f-482f-a24c-8a15ea1383b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "split = Split.VAL\n",
    "\n",
    "generate_min_proteome_kmer_lens = MIN_PROTEOME_KMER_LENS\n",
    "generate_non_self_prob_factors = NON_SELF_PROB_FACTORS\n",
    "\n",
    "selected_source_ids[split] = {\n",
    "    'A': benchmark_source_ids + get_Beam_source_ids([5,6,7], PLOT_NON_SELF_PROB_FACTORS, person_mhc_1_genotype),\n",
    "    'B': benchmark_source_ids + get_Beam_source_ids([5, 6], [0.5, 0.9, 0.99], person_mhc_1_genotype),\n",
    "    'C': benchmark_source_ids + get_Beam_source_ids([5, 6], [0.5, 0.9, 0.99], person_mhc_1_genotype),\n",
    "}\n",
    "\n",
    "fig_width_B = A4_width\n",
    "ylabel_B = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c290db5-de18-47e2-8792-4f1a46ee30fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "code = []\n",
    "for shared_c, specific_c in zip(shared_code, specific_code[split]):\n",
    "    if specific_c is not None:\n",
    "        code.append(specific_c)\n",
    "    else:\n",
    "        code.append(shared_c)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cdf3453-6ec0-486d-a14f-b655f5516ed3",
   "metadata": {},
   "source": [
    "## Construct df_decodings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9ec1c8f-07eb-4626-9535-f828b715eb3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "print(code[i])\n",
    "exec(code[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c3b164f-24b2-4efa-888f-21e50ba6ca7c",
   "metadata": {},
   "source": [
    "## Generate beam search commands"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90c82dfc-116a-4e31-b67f-0eb418292a88",
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 1\n",
    "print(code[i])\n",
    "exec(code[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f23d7bb1-e557-4b12-86bf-1acfe209158d",
   "metadata": {},
   "source": [
    "run the ``cape-beam.py`` commands generated above in a terminal of the container"
   ]
  },  
  {
   "cell_type": "markdown",
   "id": "f0e7b90e-d4de-4692-9218-27a6d001ad93",
   "metadata": {},
   "source": [
    "## Predict 3D structures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5bd5546-dbd1-4cde-95c5-b869c29811e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 2\n",
    "print(code[i])\n",
    "exec(code[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f23d7bb1-e557-4b12-86bf-1acfe209158d",
   "metadata": {},
   "source": [
    "run the following in a shell on the host system\n",
    "```\n",
    "colabfold_batch \"${CAPE}/artefacts/CAPE/colabfold/input/\" \"${CAPE}/artefacts/CAPE/colabfold/output/\" --amber --use-gpu-relax\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41c8fc31-c7de-4325-89d0-e1b3cf73b8b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 3\n",
    "print(code[i])\n",
    "exec(code[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75aa85bf-2548-48c6-a4c6-0bf3389b7bcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 4\n",
    "print(code[i])\n",
    "exec(code[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6477f9c7-ac5e-41ea-b4ab-495cc65db7af",
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 5\n",
    "print(code[i])\n",
    "exec(code[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75515e72-a9f4-4040-864a-74908ec3c9d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 6\n",
    "print(code[i])\n",
    "exec(code[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "004df4e9-c6a7-4806-aa13-2ca0ab4c9759",
   "metadata": {},
   "outputs": [],
   "source": [
    "for _, row in df_decodings.iterrows():\n",
    "    if row.seq is None or len(row.seq) == 0:\n",
    "        print(f\"Seq is missing: {row.protein_id} {row.source_id} {rename_source_ids_X[row.source_id]} {row.min_self_kmer_length} {row.non_self_prob_factor} {row.tune_mhc_1_genotype}\")\n",
    "    elif row.tm_data is None:\n",
    "        print(f\"TM data is missing: {row.protein_id} {row.source_id} {rename_source_ids_X[row.source_id]} {row.min_self_kmer_length} {row.non_self_prob_factor} {row.tune_mhc_1_genotype}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1eb6f9ac-d160-4b84-b363-4d77dc36f421",
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 7\n",
    "print(code[i])\n",
    "exec(code[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1459d3bc-d9fc-4a3e-801f-2c5471dfa141",
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 8\n",
    "print(code[i])\n",
    "exec(code[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "211b6425-7642-4aaa-aaa4-75012ca8177c",
   "metadata": {},
   "source": [
    "## Add additional columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f369b29c-9c0a-4f48-a9a9-6ebad68f8731",
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 9\n",
    "print(code[i])\n",
    "exec(code[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4174462c-bac1-4b13-b2ec-7336f1167110",
   "metadata": {},
   "source": [
    "## Run DESTRESS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "188cc5b1-6bf3-46c1-b938-2091c1024226",
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 10\n",
    "print(code[i])\n",
    "exec(code[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff17dbff-ab02-4d9d-88c1-b31ea9aec554",
   "metadata": {},
   "source": [
    "```\n",
    "Install DE-STRESS (https://github.com/wells-wood-research/de-stress) command line tool and run destress evaluations on host system\n",
    "\n",
    "PF=${CAPE}\n",
    "DESTRESS_PATH=<path where you installed de-stress>\n",
    "python ${PF}/tools/run_destress.py --destress_prog_dir_path $DESTRESS_PATH --project CAPE-Beam\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c62af6b7-0eef-4f06-9ba6-627567328ac0",
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 11\n",
    "print(code[i])\n",
    "exec(code[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22e67c61-a77a-4036-a4a9-3ff4e9677bde",
   "metadata": {},
   "source": [
    "## Plots"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08cfe0a7-bbaf-43ec-beeb-01b71b4fb105",
   "metadata": {},
   "source": [
    "### Figure X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97841608-a6b4-447a-a018-62317532967d",
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 12\n",
    "print(code[i])\n",
    "exec(code[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77d22b98-17a2-4f8a-83fb-d110fa8a7eaf",
   "metadata": {},
   "source": [
    "### Figure A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e455b635-f053-48d6-940b-1edd5884566b",
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 13\n",
    "print(code[i])\n",
    "exec(code[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89456b54-469f-4061-ab98-ad17a6d31e19",
   "metadata": {},
   "source": [
    "### Figure B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "404f4144-7155-4916-8e79-8af670098b45",
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 14\n",
    "print(code[i])\n",
    "exec(code[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ac60042-8890-4781-8f5e-452c9bca3fde",
   "metadata": {},
   "source": [
    "### Figure C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5124473-3c22-40ed-8c68-edace12da232",
   "metadata": {},
   "outputs": [],
   "source": [
    "# i = 15\n",
    "# print(code[i])\n",
    "# exec(code[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab01de04-c25a-4972-ba9b-0f536c9a3de8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# i = 16\n",
    "# print(code[i])\n",
    "# exec(code[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ccf57a9-e8f6-4974-82e2-a8e1a63ebbd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# i = 17\n",
    "# print(code[i])\n",
    "# exec(code[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81970cb1-7dab-4d40-9756-7eec10cb7c4a",
   "metadata": {},
   "source": [
    "# Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdf18419-3e8c-4cfe-a10a-dd745ecb3c7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "MIN_SELF_KMER_LENS_TEST = [5, 6]\n",
    "NON_SELF_PROB_FACTORS_TEST = [0.9]\n",
    "\n",
    "split = Split.TEST\n",
    "\n",
    "generate_min_proteome_kmer_lens = MIN_SELF_KMER_LENS_TEST\n",
    "generate_non_self_prob_factors = NON_SELF_PROB_FACTORS_TEST\n",
    "\n",
    "selected_source_ids[split] = {\n",
    "    'A': benchmark_source_ids + get_Beam_source_ids(MIN_SELF_KMER_LENS_TEST, NON_SELF_PROB_FACTORS_TEST, person_mhc_1_genotype),\n",
    "    'B': benchmark_source_ids + get_Beam_source_ids(MIN_SELF_KMER_LENS_TEST, NON_SELF_PROB_FACTORS_TEST, person_mhc_1_genotype),\n",
    "    'C': benchmark_source_ids + get_Beam_source_ids(MIN_SELF_KMER_LENS_TEST, NON_SELF_PROB_FACTORS_TEST, person_mhc_1_genotype),\n",
    "}\n",
    "\n",
    "fig_width_B = A4_width * 5/9\n",
    "ylabel_B = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f88a1d82-4521-4e67-b6e8-d6b817045a79",
   "metadata": {},
   "outputs": [],
   "source": [
    "code = []\n",
    "for shared_c, specific_c in zip(shared_code, specific_code[split]):\n",
    "    if specific_c is not None:\n",
    "        code.append(specific_c)\n",
    "    else:\n",
    "        code.append(shared_c)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2c8f48a-f1ee-4b7f-a661-e9fd94e307da",
   "metadata": {},
   "source": [
    "## Construct df_decodings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acdb2be8-dd39-4aff-9e73-208bd5e05815",
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "print(code[i])\n",
    "exec(code[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "373522e9-af78-4ee8-8592-6c5fbf7ec846",
   "metadata": {},
   "source": [
    "## Generate beam search commands"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04fa51c8-9fc7-455b-9eac-63fa9d565f24",
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 1\n",
    "print(code[i])\n",
    "exec(code[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f23d7bb1-e557-4b12-86bf-1acfe209158d",
   "metadata": {},
   "source": [
    "run the ``cape-beam.py`` commands generated above in a terminal of the container"
   ]
  },  
  {
   "cell_type": "markdown",
   "id": "cc58fac3-fdc5-4e37-898c-353bacb932ee",
   "metadata": {},
   "source": [
    "## Predict 3D structures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60c4a0d1-441d-46a4-bf0b-00cbf9b16062",
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 2\n",
    "print(code[i])\n",
    "exec(code[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0463475d-d913-4056-9c71-06439a32b99a",
   "metadata": {},
   "source": [
    "run the following in a shell on the host system\n",
    "```\n",
    "colabfold_batch \"${CAPE}/artefacts/CAPE/colabfold/input/\" \"${CAPE}/artefacts/CAPE/colabfold/output/\" --amber --use-gpu-relax\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8bc7811-63aa-45e3-9b50-d800f0056745",
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 3\n",
    "print(code[i])\n",
    "exec(code[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3b6e4f3-abfb-4c57-9f76-f8b559f0344d",
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 4\n",
    "print(code[i])\n",
    "exec(code[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0862083f-064d-42d4-b5b0-c352fc0c5943",
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 5\n",
    "print(code[i])\n",
    "exec(code[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c1c18e0-fb1e-4d96-b4cf-503b2d84dceb",
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 6\n",
    "print(code[i])\n",
    "exec(code[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ea1bb88-6e19-4bf7-b29c-a4d7c5714c59",
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 7\n",
    "print(code[i])\n",
    "exec(code[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fccc2780-6b0b-4db1-97da-78d7e2513fd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 8\n",
    "print(code[i])\n",
    "exec(code[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b69b536d-9d98-4605-b209-d18c58097e1b",
   "metadata": {},
   "source": [
    "## Add additional columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abae0776-87ae-4c90-9030-998025d14ea1",
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 9\n",
    "print(code[i])\n",
    "exec(code[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7184fe1-24fa-4993-9262-d5a93bf51ab1",
   "metadata": {},
   "source": [
    "## Run DESTRESS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c668c8c5-a2a3-403c-a6ad-06473c7515a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 10\n",
    "print(code[i])\n",
    "exec(code[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37f3ca8f-2110-43d1-8f6c-e7f6bdbe27fc",
   "metadata": {},
   "source": [
    "```\n",
    "Install DE-STRESS (https://github.com/wells-wood-research/de-stress) command line tool and run destress evaluations on host system\n",
    "\n",
    "PF=${CAPE}\n",
    "DESTRESS_PATH=<path where you installed de-stress>\n",
    "python ${PF}/tools/run_destress.py --destress_prog_dir_path $DESTRESS_PATH --project CAPE-Beam\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ac60e4a-57f5-4a66-9df9-36d870cf27b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 11\n",
    "print(code[i])\n",
    "exec(code[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8109b98c-0a49-4558-9c55-ed017fb177bf",
   "metadata": {},
   "source": [
    "## Plots"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3432b7c-ad12-4a22-9ec3-242928389f19",
   "metadata": {},
   "source": [
    "### Figure X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4362f72a-5a2d-4bbb-a2d8-2807f2139026",
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 12\n",
    "print(code[i])\n",
    "exec(code[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85a1db37-0c93-4545-880d-c6c961380d9f",
   "metadata": {},
   "source": [
    "### Figure A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4568347f-0bd1-4063-ba86-a7fd5e9c80bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 13\n",
    "print(code[i])\n",
    "exec(code[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "359c49ed-dfe6-4626-ac2f-8234e0896583",
   "metadata": {},
   "source": [
    "### Figure B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2787ec0-5e57-4274-9d89-af9487d053a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 14\n",
    "print(code[i])\n",
    "exec(code[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10e19aee-f97a-42ea-8cdf-67b577e87d55",
   "metadata": {},
   "source": [
    "### Figure C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb1737bf-08cf-4137-9245-895c0cd29c9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 15\n",
    "print(code[i])\n",
    "exec(code[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66d7167f-4553-45a3-a6f1-9f8c515393c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 16\n",
    "print(code[i])\n",
    "exec(code[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f849b97-8feb-41c4-96a7-ef15d46e7fe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 17\n",
    "print(code[i])\n",
    "exec(code[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4371a0a-ead2-4798-bbc9-7db70f53dce2",
   "metadata": {},
   "source": [
    "## Other Genotypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab0d0aaa-9711-4ac7-ad59-ec0b2db816a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_mhc_1_genotypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c6e85e2-ddc4-4476-8947-99e8f081ffbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "set_kmers_presented(df_decodings, MHC_1_PREDICTOR_EVAL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "689de355-631b-4b4a-bac5-fd1b764f6d6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "tm_scores_per_mhc_1_genotype = {}\n",
    "\n",
    "kmers_presented_per_mhc_1_genotype_template = {}\n",
    "kmers_presented_per_mhc_1_genotype_beam = {}\n",
    "kmers_presented_per_mhc_1_genotype_beam_vs_template = {}\n",
    "kmers_presented_per_mhc_1_genotype_beam_frac = {}\n",
    "\n",
    "min_self_kmer_length = 5\n",
    "for mhc_1_genotype in all_mhc_1_genotypes:\n",
    "    _df = df_decodings.query(f\"eval_mhc_1_genotype == '{mhc_1_genotype}'\")\n",
    "    \n",
    "    tm_scores_per_mhc_1_genotype[mhc_1_genotype] = [_df.query(f\"source_id not in {benchmark_source_ids} and min_self_kmer_length == {min_self_kmer_length} and protein_id == '{_protein_id}'\").iloc[0].tm_data[0] for _protein_id in specific_proteins[split]]\n",
    "\n",
    "    kmers_presented_per_mhc_1_genotype_beam[mhc_1_genotype] = [len(_df.query(f\"source_id not in {benchmark_source_ids} and protein_id == '{_protein_id}'\").iloc[0].kmers_presented) for _protein_id in specific_proteins[split]]\n",
    "    kmers_presented_per_mhc_1_genotype_template[mhc_1_genotype] = [len(_df.query(f\"source_id == 'template' and protein_id == '{_protein_id}'\").iloc[0].kmers_presented) for _protein_id in specific_proteins[split]]\n",
    "    kmers_presented_per_mhc_1_genotype_beam_vs_template[mhc_1_genotype] = np.array(kmers_presented_per_mhc_1_genotype_beam[mhc_1_genotype])/np.array(kmers_presented_per_mhc_1_genotype_template[mhc_1_genotype])\n",
    "    kmers_presented_per_mhc_1_genotype_beam_frac[mhc_1_genotype] = np.array(kmers_presented_per_mhc_1_genotype_beam[mhc_1_genotype])/[np.sum(get_possible_peptides(_df.query(f\"source_id not in {benchmark_source_ids} and protein_id == '{_protein_id}'\").iloc[0].immuno_chains, [8, 9, 10])) for _protein_id in specific_proteins[split]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29c4197a-1139-4bf8-bd2f-190c95552dac",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.array(tm_scores_per_mhc_1_genotype[all_mhc_1_genotypes[0]])  # your x values here\n",
    "y = np.array(tm_scores_per_mhc_1_genotype[all_mhc_1_genotypes[1]])  # your y values here\n",
    "\n",
    "X = sm.add_constant(x)  # add intercept data\n",
    "\n",
    "model = sm.OLS(y, X).fit()\n",
    "\n",
    "intercept, slope = model.params\n",
    "# Get standard errors\n",
    "se_intercept, se_slope = model.bse\n",
    "\n",
    "# Test H0: Intercept = 0\n",
    "t_intercept = (intercept - 0) / se_intercept\n",
    "p_intercept = 2 * (1 - stats.t.cdf(np.abs(t_intercept), df=model.df_resid))\n",
    "print(f\"p-value intercept == 0: {p_intercept}\")\n",
    "\n",
    "# Test H0: Slope = 1\n",
    "t_slope = (slope - 1) / se_slope\n",
    "p_slope = 2 * (1 - stats.t.cdf(np.abs(t_slope), df=model.df_resid))\n",
    "print(f\"p-value slope == 1:{p_slope}\")\n",
    "\n",
    "affine_estimate = f\"y = {intercept:.3f} + {slope:.3f}x\"\n",
    "p_values = f\"p-values:\\n   intercept == 0: {p_intercept:.3f}\\n   slope == 1: {p_slope:.3f}\"\n",
    "print(affine_estimate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7acaea95-f26d-4817-a58e-c948cb894617",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sense check (estimate (y - x) = intercept + slope * x)... so the test vs 0 makes sense\n",
    "x = np.array(tm_scores_per_mhc_1_genotype[all_mhc_1_genotypes[0]])\n",
    "y = np.array(tm_scores_per_mhc_1_genotype[all_mhc_1_genotypes[1]]) - np.array(tm_scores_per_mhc_1_genotype[all_mhc_1_genotypes[0]])\n",
    "X = sm.add_constant(x)\n",
    "\n",
    "model = sm.OLS(y, X).fit()\n",
    "\n",
    "intercept_check, slope_check = model.params\n",
    "slope_check += 1\n",
    "affine_estimate_check = f\"y = {intercept_check:.3f} + {slope_check:.3f}x\"\n",
    "print(affine_estimate_check)\n",
    "print(model.pvalues)\n",
    "\n",
    "assert all([np.isclose(p1, p2) for (p1, p2) in zip([p_intercept, p_slope], model.pvalues)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bed46f59-dfec-44b7-a861-8618765f7fff",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(A4_width, A4_height/3.4))\n",
    "gs = gridspec.GridSpec(1, # rows\n",
    "                       2, # cols\n",
    "                       width_ratios=[1, 1],\n",
    "                       height_ratios=[1],\n",
    "                       hspace=0.1,\n",
    "                       wspace=0.3,\n",
    "                      )\n",
    "\n",
    "# TM-scores vs TM-scores\n",
    "ax = fig.add_subplot(gs[0, 0])\n",
    "ax.text(-.1, 1.2, f\"{string.ascii_lowercase[0]})\", transform=ax.transAxes, fontsize=15, fontweight='bold', va='top', ha='right')\n",
    "ax.set_title('TM-scores')\n",
    "ax.set_xlabel('primary genotype')\n",
    "ax.set_ylabel('alternative genotype')\n",
    "sns.scatterplot(\n",
    "    x=tm_scores_per_mhc_1_genotype[all_mhc_1_genotypes[0]], \n",
    "    y=tm_scores_per_mhc_1_genotype[all_mhc_1_genotypes[1]],\n",
    "    ax=ax\n",
    ")\n",
    "ax.plot([0, 1.], [intercept, intercept + slope], label=f'regression', color='lightblue', linestyle='--')\n",
    "ax.set_xlim((0., 1.))\n",
    "ax.set_ylim((0., 1.))\n",
    "\n",
    "ax.text(x=0.05, y=0.75, s=f\"{affine_estimate}\\n{p_values}\")\n",
    "\n",
    "\n",
    "\n",
    "# presented 8-10mers not in proteome as % of template\n",
    "ax = fig.add_subplot(gs[0, 1])\n",
    "ax.text(-.1, 1.2, f\"{string.ascii_lowercase[1]})\", transform=ax.transAxes, fontsize=15, fontweight='bold', va='top', ha='right')\n",
    "ax.set_title('relative number of \\n potentially immunogenic peptides')\n",
    "ax.set_xlabel('primary genotype [frac of 8-10mers]')\n",
    "ax.set_ylabel('alternative genotype [frac of 8-10mers]')\n",
    "sns.scatterplot(\n",
    "    # x=kmers_presented_per_mhc_1_genotype_beam_vs_template[all_mhc_1_genotypes[0]], \n",
    "    # y=kmers_presented_per_mhc_1_genotype_beam_vs_template[all_mhc_1_genotypes[1]],\n",
    "    x=kmers_presented_per_mhc_1_genotype_beam_frac[all_mhc_1_genotypes[0]], \n",
    "    y=kmers_presented_per_mhc_1_genotype_beam_frac[all_mhc_1_genotypes[1]],\n",
    "    ax=ax\n",
    ")\n",
    "ax.axvline(np.mean(kmers_presented_per_mhc_1_genotype_beam_frac[all_mhc_1_genotypes[0]]), color='lightblue', linestyle='--')\n",
    "ax.axhline(np.mean(kmers_presented_per_mhc_1_genotype_beam_frac[all_mhc_1_genotypes[1]]), color='lightblue', linestyle='--')\n",
    "\n",
    "ax.xaxis.set_major_formatter(PercentFormatter(1.0))\n",
    "ax.yaxis.set_major_formatter(PercentFormatter(1.0))\n",
    "\n",
    "for mhc_1_genotype in all_mhc_1_genotypes:\n",
    "    print(np.mean(kmers_presented_per_mhc_1_genotype_beam_frac[mhc_1_genotype]))     \n",
    "\n",
    "\n",
    "if SAVE_FIGURES:\n",
    "    fig.savefig(join(G.ENV.ARTEFACTS, \"eval\", \"figures\", G.DOMAIN, \n",
    "        f\"figure_G_{split}.pdf\"), \n",
    "        bbox_inches='tight'\n",
    "    )\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48b58688-05d3-4f5e-ad44-cdb320a5f907",
   "metadata": {},
   "source": [
    "# Shutdown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d76870c0-0d13-47b9-9d6f-ece4b34c1f98",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(specific_proteins_file_path, \"wb\") as f:\n",
    "    pickle.dump(specific_proteins, f)    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
